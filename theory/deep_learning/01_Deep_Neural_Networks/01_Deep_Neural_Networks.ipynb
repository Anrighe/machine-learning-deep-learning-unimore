{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Networks\n",
    "\n",
    "Usando i metodi classici di machine learning fissando le feature, sopra una certa quantità di dati non si otterranno miglioramenti. Questo non è vero per le reti neurali: una rete deep, normalmente, all'aumentare dei dati di training continua a migliorare.\n",
    "\n",
    "![Deep Neural Networks1](images/01_Deep_Neural_Networks1.png)\n",
    "\n",
    "Nel caso di un metodo di machine learning tradizionale, all'inizio c'è sempre la fase di ***feature extraction***, che non è collegata alla fase di ottimizzazione del modello in quanto viene fatta prima. Questa cosa però non implica che ci possano essere delle feature migliori.\n",
    "\n",
    "Nel caso del Deep Learning, la parte di ***feature extraction*** e ***apprendimento dei parametri*** sono collegate e vengono quindi fatte insieme. Man mano che fornisco dati di training al sistema cambiano le feature &rarr; il modello di Deep Learning estrae delle feature sempre migliori.\n",
    "\n",
    "La maggior parte dei metodi di machine learning dipende da feature ***hand-crafted***, mentre gli algoritmi di Deep Learning permettono di imparare le migliori feature per il problema che si sta affrontando.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Classifier\n",
    "\n",
    "Operatore che generalizza la logistic regression in un contesto multiclasse. Il softmax per la classe $j$-esima di $z$ è definito come:\n",
    "\n",
    "### $softmax_j(z) = \\frac{e^{z_j}}{\\sum_{k=1}^{K} e^{z_k}}$\n",
    "\n",
    "Il softmax permette di prendere un vettore di score e trasformarlo in un vettore di probabilità che sommano a 1.\n",
    "\n",
    "Per allenare il classificatore viene usa la ***cross-entropy loss***:\n",
    "\n",
    "### $L_i = - \\underset{i}{\\sum} y_i^{true} \\log y^{pred}_i$\n",
    "\n",
    "Nella cross entropy c'è un vettore one not dove c'è un $1$ in corrispondenza della label corretta e poi il vettore delle predizioni per tutte le $k$ classi.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuron\n",
    "\n",
    "![Deep Neural Networks2](images/01_Deep_Neural_Networks2.png)\n",
    "\n",
    "Un neurone è costituito da:\n",
    "- un nucleo &rarr; cellula che rappresenta il neurone\n",
    "- dendriti &rarr; connettono il nucleo con altri neuroni\n",
    "- sinapsi &rarr; gelatina che ingloba i dendriti e ha lo scopo di amplificare o sopprimere il segnale che arriva sul dendrito\n",
    "\n",
    "Una volta che il segnale arriva al nucleo, il segnale viene unito con un processo biochimico e poi valuta quanto sia forte il segnale come combinazione di quello dati in ingresso. \n",
    "\n",
    "Se il segnale è abbastanza forte, il neurone si dice <span style=\"color:gold\">***attivo***</span> e invia un segnale di output.\n",
    "\n",
    "Se il segnale è debole, il neurone si dice <span style=\"color:gold\">***spento***</span> e non invia un segnale di output.\n",
    "\n",
    "Da un punto di vista formale, il neurone è rappresentabile nel seguente modo:\n",
    "\n",
    "![Deep Neural Networks3](images/01_Deep_Neural_Networks3.png)\n",
    "\n",
    "- Ho una serie di ingressi $x_0$, $x_1$, $x_2$, ... che rappresentano gli input che arrivano da altri neuroni.\n",
    "- La sinapsi la rappresento con un peso $w_0$, $w_1$, $w_2$, ... che rappresenta quanto il segnale che arriva da un neurone è importante per il neurone in questione.\n",
    "- Internamente al nucleo i segnali sono raccolti e sommati\n",
    "- Per decidere se un neurone sarà attivo o spento utilizzo una funzione di soglia &rarr; ***activation function*** &rarr; ad esempio la ***sigmoide***.\n",
    "\n",
    "Se cercassimo i $w$ usando la binary cross entropy, avremmo una logistic regression a due classi. Se invece avessimo 10 neuroni, uno per ogni classe con al posto della sigmoide la softmax e l'allenassimo con la cross entropy si avrebbe la logistic regression multiclasse.\n",
    "\n",
    "Quindi un neurone o uno strato di neuroni, è assimilabile a una logistic regression a due classi se usa la sigmoide o a n-classi se sono tanti neuroni con la softmax.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
