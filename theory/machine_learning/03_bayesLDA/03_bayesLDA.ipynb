{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Error Rate\n",
    "\n",
    "Dato un dataset di esempio $D = {(x_i, y_i), i = 1 : N}$ e una funzione $f : ‚Ñù^D$ &rarr; $Y$, la Classification Error Rate √® l'<u>errore medio su **N** elementi</u> di $f$ su $D$ (conto quante volte sbaglio), ed √® definito come:\n",
    "\n",
    "# $Err(f, D) = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{ùïÄ}_{(y_i \\neq f(x_i))}$\n",
    "\n",
    "- $f(x_i)$ √® la classe predetta\n",
    "- $y_i$ √® la classe reale di appartenenza\n",
    "- ùïÄ √® la funzione indicatrice, che vale 1 se la condizione √® vera, 0 altrimenti.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Accuracy Rate\n",
    "\n",
    "Dato un dataset di esempio $D = {(x_i, y_i), i = 1 : N}$ e una funzione $f : ‚Ñù^D$ &rarr; $Y$, la Classification Accuracy Rate <u>misura della media di quante volte ci prendo</u>:\n",
    "\n",
    "# $Acc(f, D) = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{ùïÄ}_{(y_i = f(x_i))}$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior Probability\n",
    "\n",
    "Se supponiamo che la funzione **f** precedentemente menzionata sia una funzione che fornisce in output una probabilit√†, allora stiamo usando un classificatore probabilistico.\n",
    "\n",
    "Supponiamo che la probabilit√† di vedere un elemento che appartiene a una certa classe **c** sia $P(Y = c)$, dove quello dentro alle parentesi, $Y = c$, √® l'evento che stiamo considerando, ovvero che l'elemento appartenga alla classe **c**. Questa probabilit√† si indica con la notazione:\n",
    "\n",
    "# $P(Y = c) = \\pi_c$\n",
    "\n",
    "E normalmente si chiama <span style=\"color:gold;\">**prior probability**</span> (o probabilit√† a priori), perch√© di fatto non dipende da nessun elemento del dataset, ma √® una probabilit√† che viene assegnata a priori, prima di vedere il dataset (ad esempio probabilit√† a priori di capire se una persona √® maschio o femmina prima di guardarla in faccia).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood\n",
    "\n",
    "Viene definita come <span style=\"color:gold;\">likelyhood</span> la densit√† di probabilit√† di vedere un vettore $x \\in ‚Ñù^D$ che appartiene alla classe **c** come:\n",
    "\n",
    "# $p(X = x | Y = c) = \\phi_c(x)$\n",
    "\n",
    "- ***p*** (probabilit√†) in questo caso √® una densit√†, quindi √® minuscola\n",
    "    - La densit√† √® una funzione il cui integrale fa 1, mentre la probabilit√† √® gi√† l'integrale della densit√†\n",
    "\n",
    "Fissata la classe **c**, qual √® la probabilit√† che **X** sia uguale a **x**.\n",
    "La likelyhood misura quanto, fissata la classe, quello che sto guardando √® coerente con la mia classe.\n",
    "\n",
    "*Esempio*: fisso la classe maschio, guardo la foto di una persona con la barba e ottengo (presumibilmente) una probabilit√† alta di essere maschio.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A-posteriori probability\n",
    "\n",
    "Per computare la probabilit√† che un elemento appartenga a una certa classe, si usa il <span style=\"color:gold;\">**teorema di Bayes**</span>:\n",
    "\n",
    "# $P(Y = c | X = x) = \\frac{P(X = x | Y = c) P(Y = c)}{\\sum_{c' \\in ùí¥}P(X = x, Y = c')} = \\frac{\\phi_c(x) \\pi_c}{\\sum_{c' \\in ùí¥}\\phi_{c'}(x) \\pi_{c'}}$\n",
    "\n",
    "Dove la probabilit√† di che **Y** appartenga alla classe **c** dato **X** uguale a **x** √® uguale alla:\n",
    "\n",
    "# $\\frac{{\\text{ likelihood }} * {\\text{ prior probability }}}{\\text{normalizing constant}}$\n",
    "\n",
    "dove la ***normalizing constant*** √® la sommatoria di tutti i possibili valori che pu√≤ assumere **Y** (ovvero tutte le classi possibili), quindi la somma delle quantit√† che si hanno sopra per tutte le classi.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification strategies\n",
    "\n",
    "Quando dobbiamo classificare, possiamo approcciare il problema in due modi. \n",
    "\n",
    "Supponendo di avere un dataset $D = (x_i, y_i)_{i=1..N}$ con $x_i$ vettore di feature e $y_i$ la classe, con in totale **k** classi $c_i | i = 1..k$ e un generico test sample $\\hat{x}$:\n",
    "- ### Maximum Likelihood Classification:\n",
    "  - Dal dataset **D** impara una funzione di likelyhood per ogni classe $c_i$ $P(x | c_i)$\n",
    "  - Poi prendo $\\hat{x}$ e lo passo a tutte le funzioni di likelyhood &rarr; $P(\\hat{x} | c_i)$\n",
    "  - Quella che mi d√† il valore pi√π alto sar√† la classe da attribuire a $\\hat{x}$ &rarr; $\\hat{c} = argmax_c P(\\hat{x}|c)$\n",
    "    - Sto cercando la classe che massimizza il likelihood\n",
    "  \n",
    "- ### Maximum A-Posteriori Classification:\n",
    "  - Dal dataset **D** impara una funzione di likelyhood per ogni classe $c_i$ $P(x | c_i)$\n",
    "  - Da **D** imparo anche la probabilit√† a priori per ogni calsse $c_i$ $P(c_i)$\n",
    "  - dato $\\hat{x}$ applico la regola di Bayes per ottenere $P(c_i | \\hat{x})$\n",
    "  - $\\hat{c} = argmax_c P(c_i | \\hat{x})$\n",
    "    - Sto cercando la classe che massimizza\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Bayes Optimal Classifier\n",
    "\n",
    "## $f_B(x) = argmax_{c \\in ùí¥} P(Y = c | X = x) = argmax_{c \\in ùí¥} \\phi_c(x) \\pi_c$\n",
    "\n",
    "Da un punto di vista teorico, il classificatore baesyano minimizza indirettamente l'errore, perch√© assegno sempre l'errore che ha pi√π probabilit√† di essere giusta, ma non √® utilizzabile nella pratica perch√© X=x non √® finita e perch√© dipende dalle funzioni che ha imparato il classificatore (che potrebbero essere sbaliate in quanto potrebbe aver appreso un fenomeno non correttamente).\n",
    "\n",
    "Quindi tra tutti i possibili errori attesi, il classificatore baesyano mi fornisce il pi√π basso.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prodotto di probabilit√†\n",
    "Se ho due variabili aleatorie **x**, **y**, la probabilit√† congiunta √® espressa come $P(x, y)$.\n",
    "\n",
    "Se la voglio valutare in un caso specifico sar√† $P(x=\\hat{x}, y=\\hat{y})$, dove **x** e **y** sono i nomi delle variabili e $\\hat{x}$ e $\\hat{y}$ sono due osservazioni &rarr; <span style=\"color:gold;\">**Probabilit√† congiunta**</span> (joint probability), perch√© √® la probabilit√† che questi due eventi accadano insieme.\n",
    "\n",
    "La regola del prodotto collega la probabilit√† congiunta con la probabilit√† condizionate, in quanto:\n",
    "\n",
    "# $P(x, y) = P(x | y) P(y)$\n",
    "\n",
    "# $P(x | y) = \\frac{P(x, y)}{P(y)}$\n",
    "\n",
    "La probabilit√† a posteriori, applicando la regola di Bayes sar√†:\n",
    "\n",
    "# $P(y | x) = \\frac{P(x | y) * P(y)}{P(x)}= \\frac{P(x, y)}{P(x)}$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density estimation the JOINT Density JD\n",
    "\n",
    "Se possiamo stimare la <span style=\"color:gold;\">**joint probability**</span> $P(X = x, Y = c)$, ovvero la probabilit√† che **X** sia uguale a **x** e che **Y** sia uguale a **c**, allora utilizzando la regola del prodotto delle probabilit√† posso trovare tutte le probabilit√† condizionate.\n",
    "\n",
    "\n",
    "Per fare density esimation posso usare una JD Table:\n",
    "\n",
    "![JD](./images/bayesLDA1.png)\n",
    "\n",
    "Tramite conteggio all'interno del mio dataset posso verificare la probabilit√† di quante volte sia presente all'interno del mio dataset una combinazione di variabili aleatorie rispetto al totale.\n",
    "\n",
    "Problemi:\n",
    "- La JD table funziona solo per le variabili numerabili (nel continuo non funziona)\n",
    "- Se le variabili possono assumere molti valori, le possibili configurazioni possono salire molto velocemente\n",
    "- Molto spesso le JD Table sono soggette a overfitting.\n",
    "\n",
    "# Overfitting\n",
    "Siccome il nostro dataset non rappresenta il fenomeno, ma una rappresentazione approssimata del vero fenomeno, pu√≤ non coprire tutti i possibili casi. Quindi costruendo la JD table su un determinato dataset potrebbe voler dire avere probabilit√† 0 per alcuni casi che invece potrebbero accadere.\n",
    "Se la mia tabella di densit√† di probabilit√† √® talmente specializzata su questo dataset, non rappresenta bene il fenomeno e quindi non √® generalizzabile.\n",
    "Molto spesso uno stimatore di densit√† di probabilit√† √® soggetto a overfitting &rarr; il mio classificatore ha visto una porzione di fenomeno troppo piccola.\n",
    "\n",
    "Al posto di stimare $P(X = x, Y = c)$, che tiene conto di tutte le possibili combinazioni, posso stimare $P(x|c)$, cio√® \"fissata la classe qual √® la probabilit√† di **x**?\n",
    "\n",
    "Bloccando la classe, l'overfitting non c'√®!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametric Maximum Likelihood Density Estimation\n",
    "\n",
    "Viene utilizzato nel caso continuo, dove definisco una determinata funzione $p(x|\\theta)$, dove $\\theta$ √® un set di parametri.\n",
    "La funzione √® nota, ad esempio una delle pi√π usate √® la gaussiana.\n",
    "\n",
    "Cerco il set di parametri \\theta che massimizza il prodotto su tutto il dataset di $p(x|\\theta)$, ovvero il prodotto della likelihood di ogni singolo elemento del dataset:\n",
    "\n",
    "# $\\hat{\\theta} = argmax_{\\theta} \\prod_{x_i \\in D} p(x_i | \\theta)$\n",
    "\n",
    "La produttoria non √® molto bella da usare perch√© quando ci sono dei numeri molto prossimi allo zero, anche tutta la quantit√† risultante tender√† a zero.\n",
    "Per evitare questo problema si usa il logaritmo, che trasforma la produttoria in una sommatoria:\n",
    "\n",
    "# $\\hat{\\theta} = argmax_{\\theta} \\sum_{x_i \\in D} log(p(x_i | \\theta))$\n",
    "\n",
    "Quando passo ai logaritmi, il logaritmo di una produttoria √® uguale alla sommatoria dei logaritmi.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-parametric Estimation\n",
    "\n",
    "Per ogni possibile valore che pu√≤ assumere una variabile, conto all'interno del dataset quanti elementi assumono quel determinato valore. Costruisco un istogramma $H(x)$ contando il numero di valori che assume la variabile **x*** e lo divido per il totale degli elementi del dataset (normalizzo).\n",
    "\n",
    "![non-parametric](./images/bayesLDA2.png)\n",
    "\n",
    "Ottengo cos√¨ una densit√† di probabilit√†\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un modello non parametrico, per costruzione pu√≤ rappresentare qualunque funzione, mentre nel modello parametrico scelgo la funzione prima.\n",
    "\n",
    "Esempio: dico che la funzione √® una gaussiana, ma se il fenomeno non √® una gaussiano perdo informazione  (se il fenomeno non √® \"a campana\").\n",
    "\n",
    "Quindi, perch√© non fare sempre una stima di densit√† non parametrica?\n",
    "Perch√© ha tre problemi:\n",
    "1. Ha un problema di maneggiabilit√† nel momento in cui il numero di valori che pu√≤ assumere ***x*** diventa molto alto\n",
    "2. Problema di overfitting che non ho con la versione parametrica perch√© nel caso io assuma che la funzione sia una gaussiana, \"interpolo\" dove non ho dati.\n",
    "3. Non so come discretizzare l'asse delle x, ovvero non so come dividere l'asse delle x in intervalli. La distribuzione potrebbe non essere uguale se vado di 5 in 5 o di 20 in 20.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuzione Gaussiana\n",
    "\n",
    "**X** variabile che segue la distribuzione gaussiana con media $\\mu$ e varianza $\\sigma^2$ &rarr; $X \\sim \\mathcal{Norm}(\\mu, \\sigma^2)$ ha funzione di densit√† di probabilit√† (ovvero la probabilit√† di ottenere un valore specifico (**x**) all'interno di quella distribuzione):\n",
    "\n",
    "# $p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimostrazione\n",
    "\n",
    "Dato un dataset **D** di **N** elementi, l'equazione della gaussiana parametrica √®:\n",
    "\n",
    "## $p(x|\\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$\n",
    "\n",
    "Dove il likelihood √®:\n",
    "\n",
    "## $L(\\mu, \\sigma^2) = \\prod_{i=1}^{N} p(x_i|\\mu, \\sigma^2) = \\prod_{i=1}^{N} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}}$\n",
    "\n",
    "Uso il logaritmo per convertire la produttoria in sommatoria (il logarimo di un prodotto √® la somma dei logaritmi):\n",
    "\n",
    "## $L(\\mu, \\sigma^2) = \\sum_{i=1}^{N} log(\\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}})$\n",
    "\n",
    "Avendo nuovamente il logaritmo di un prodotto, lo scompongo nella somma dei logaritmi:\n",
    "\n",
    "## $L(\\mu, \\sigma^2) = \\sum_{i=1}^{N} log(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}) + log(e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}})$\n",
    "\n",
    "Posso semplificare il secondo termine perch√© il logaritmo naturale di un esponenziale √® l'esponente:\n",
    "\n",
    "## $L(\\mu, \\sigma^2) = \\sum_{i=1}^{N} log(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}) - \\frac{(x_i-\\mu)^2}{2\\sigma^2}$\n",
    "\n",
    "Adesso voglio fare la derivata rispetto a $\\mu$:\n",
    "\n",
    "## $\\frac{\\partial L}{\\partial \\mu} = \\sum_{i=1}^{N} \\frac{\\partial}{\\partial \\mu} log(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}) - \\frac{\\partial}{\\partial \\mu} \\frac{(x_i-\\mu)^2}{2\\sigma^2}$\n",
    "\n",
    "Dove il primo termine si semplifica <u>perch√® non dipende da</u> $\\mu$:\n",
    "\n",
    "## $\\sum_{i=1}^{N} - \\frac{(x_i-\\mu)^2}{\\sigma^2}$\n",
    "\n",
    "E facendo la derivata del secondo termine ($a(x-b)^n$ che diventa $a n (x-b)^{n-1}$) e ponendo uguale a 0:\n",
    "\n",
    "## $\\sum_{i=1}^{N} \\frac{2(x_i-\\mu)}{2\\sigma^2} = 0$\n",
    "\n",
    "Dal momento che $\\frac{1}{\\sigma^2}$ non dipende da **x**, posso portarlo fuori dalla sommatoria:\n",
    "\n",
    "## $\\frac{1}{\\sigma^2} \\sum_{i=1}^{N} \\frac{(x_i-\\mu)}{2} = 0$\n",
    "\n",
    "Posso moltiplicare da entrambe le parti per $\\sigma^2$ e semplificare il 2:\n",
    "\n",
    "## $\\sum_{i=1}^{N} (x_i-\\mu) = 0$\n",
    "\n",
    "Spezzo la sommatoria:\n",
    "\n",
    "## $\\sum_{i=1}^{N} x_i = \\sum_{i=1}^{N} \\mu$\n",
    "\n",
    "Suppongo che il dataset **D** sia composto da **N** elementi. Se ho **N** elementi, $\\mu$ nella sommatoria lo sommo **N** volte, quindi:\n",
    "\n",
    "## $\\sum_{i=1}^{N} x_i = N \\mu$\n",
    "\n",
    "Dato che devo risolvere per $\\mu$, la porto a sinistra e ottengo la media:\n",
    "\n",
    "## $\\frac{\\sum_{i=1}^N x_i}{N} = \\mu$\n",
    "\n",
    "---\n",
    "\n",
    "![derivate](./images/derivate.png)\n",
    "\n",
    "Per $\\sigma$ √® la stessa cosa, ma devo fare la derivata rispetto a $\\sigma^2$:\n",
    "\n",
    "## $\\frac{\\partial L}{\\partial \\sigma^2}$ &rarr; $\\sum_{i=1}^{N} log(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}) - \\frac{(x_i-\\mu)^2}{2\\sigma^2}$\n",
    "\n",
    "Si ottiene:\n",
    "\n",
    "\n",
    "```\n",
    "Per l'esame saper costruire la Likelihood di una funzione\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
