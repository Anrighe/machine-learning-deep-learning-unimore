{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Error Rate\n",
    "\n",
    "Dato un dataset di esempio $D = {(x_i, y_i), i = 1 : N}$ e una funzione $f : ‚Ñù^D$ &rarr; $Y$, la Classification Error Rate √® l'<u>errore medio su **N** elementi</u> di $f$ su $D$ (conto quante volte sbaglio), ed √® definito come:\n",
    "\n",
    "# $Err(f, D) = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{ùïÄ}_{(y_i \\neq f(x_i))}$\n",
    "\n",
    "- $f(x_i)$ √® la classe predetta\n",
    "- $y_i$ √® la classe reale di appartenenza\n",
    "- ùïÄ √® la funzione indicatrice, che vale 1 se la condizione √® vera, 0 altrimenti.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Accuracy Rate\n",
    "\n",
    "Dato un dataset di esempio $D = {(x_i, y_i), i = 1 : N}$ e una funzione $f : ‚Ñù^D$ &rarr; $Y$, la Classification Accuracy Rate <u>misura della media di quante volte ci prendo</u>:\n",
    "\n",
    "# $Acc(f, D) = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{ùïÄ}_{(y_i = f(x_i))}$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior Probability\n",
    "\n",
    "Se supponiamo che la funzione **f** precedentemente menzionata sia una funzione che fornisce in output una probabilit√†, allora stiamo usando un classificatore probabilistico.\n",
    "\n",
    "Supponiamo che la probabilit√† di vedere un elemento che appartiene a una certa classe **c** sia $P(Y = c)$, dove quello dentro alle parentesi, $Y = c$, √® l'evento che stiamo considerando, ovvero che l'elemento appartenga alla classe **c**. Questa probabilit√† si indica con la notazione:\n",
    "\n",
    "# $P(Y = c) = \\pi_c$\n",
    "\n",
    "E normalmente si chiama <span style=\"color:gold;\">**prior probability**</span> (o probabilit√† a priori), perch√© di fatto non dipende da nessun elemento del dataset, ma √® una probabilit√† che viene assegnata a priori, prima di vedere il dataset (ad esempio probabilit√† a priori di capire se una persona √® maschio o femmina prima di guardarla in faccia).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood\n",
    "\n",
    "Viene definita come <span style=\"color:gold;\">likelyhood</span> la densit√† di probabilit√† di vedere un vettore $x \\in ‚Ñù^D$ che appartiene alla classe **c** come:\n",
    "\n",
    "# $p(X = x | Y = c) = \\phi_c(x)$\n",
    "\n",
    "- ***p*** (probabilit√†) in questo caso √® una densit√†, quindi √® minuscola\n",
    "    - La densit√† √® una funzione il cui integrale fa 1, mentre la probabilit√† √® gi√† l'integrale della densit√†\n",
    "\n",
    "Fissata la classe **c**, qual √® la probabilit√† che **X** sia uguale a **x**.\n",
    "La likelyhood misura quanto, fissata la classe, quello che sto guardando √® coerente con la mia classe.\n",
    "\n",
    "*Esempio*: fisso la classe maschio, guardo la foto di una persona con la barba e ottengo (presumibilmente) una probabilit√† alta di essere maschio.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A-posteriori probability\n",
    "\n",
    "Per computare la probabilit√† che un elemento appartenga a una certa classe, si usa il <span style=\"color:gold;\">**teorema di Bayes**</span>:\n",
    "\n",
    "# $P(Y = c | X = x) = \\frac{P(X = x | Y = c) P(Y = c)}{\\sum_{c' \\in ùí¥}P(X = x, Y = c')} = \\frac{\\phi_c(x) \\pi_c}{\\sum_{c' \\in ùí¥}\\phi_{c'}(x) \\pi_{c'}}$\n",
    "\n",
    "Dove la probabilit√† di che **Y** appartenga alla classe **c** dato **X** uguale a **x** √® uguale alla:\n",
    "\n",
    "# $\\frac{{\\text{ likelihood }} * {\\text{ prior probability }}}{\\text{normalizing constant}}$\n",
    "\n",
    "dove la ***normalizing constant*** √® la sommatoria di tutti i possibili valori che pu√≤ assumere **Y** (ovvero tutte le classi possibili), quindi la somma delle quantit√† che si hanno sopra per tutte le classi.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification strategies\n",
    "\n",
    "Quando dobbiamo classificare, possiamo approcciare il problema in due modi. \n",
    "\n",
    "Supponendo di avere un dataset $D = (x_i, y_i)_{i=1..N}$ con $x_i$ vettore di feature e $y_i$ la classe, con in totale **k** classi $c_i | i = 1..k$ e un generico test sample $\\hat{x}$:\n",
    "- ### Maximum Likelihood Classification:\n",
    "  - Dal dataset **D** impara una funzione di likelyhood per ogni classe $c_i$ $P(x | c_i)$\n",
    "  - Poi prendo $\\hat{x}$ e lo passo a tutte le funzioni di likelyhood &rarr; $P(\\hat{x} | c_i)$\n",
    "  - Quella che mi d√† il valore pi√π alto sar√† la classe da attribuire a $\\hat{x}$ &rarr; $\\hat{c} = argmax_c P(\\hat{x}|c)$\n",
    "    - Sto cercando la classe che massimizza il likelihood\n",
    "  \n",
    "- ### Maximum A-Posteriori Classification:\n",
    "  - Dal dataset **D** impara una funzione di likelyhood per ogni classe $c_i$ $P(x | c_i)$\n",
    "  - Da **D** imparo anche la probabilit√† a priori per ogni calsse $c_i$ $P(c_i)$\n",
    "  - dato $\\hat{x}$ applico la regola di Bayes per ottenere $P(c_i | \\hat{x})$\n",
    "  - $\\hat{c} = argmax_c P(c_i | \\hat{x})$\n",
    "    - Sto cercando la classe che massimizza\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Bayes Optimal Classifier\n",
    "\n",
    "## $f_B(x) = argmax_{c \\in ùí¥} P(Y = c | X = x) = argmax_{c \\in ùí¥} \\phi_c(x) \\pi_c$\n",
    "\n",
    "Da un punto di vista teorico, il classificatore baesyano minimizza indirettamente l'errore, perch√© assegno sempre l'errore che ha pi√π probabilit√† di essere giusta, ma non √® utilizzabile nella pratica perch√© X=x non √® finita e perch√© dipende dalle funzioni che ha imparato il classificatore (che potrebbero essere sbaliate in quanto potrebbe aver appreso un fenomeno non correttamente).\n",
    "\n",
    "Quindi tra tutti i possibili errori attesi, il classificatore baesyano mi fornisce il pi√π basso.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prodotto di probabilit√†\n",
    "Se ho due variabili aleatorie **x**, **y**, la probabilit√† congiunta √® espressa come $P(x, y)$.\n",
    "\n",
    "Se la voglio valutare in un caso specifico sar√† $P(x=\\hat{x}, y=\\hat{y})$, dove **x** e **y** sono i nomi delle variabili e $\\hat{x}$ e $\\hat{y}$ sono due osservazioni &rarr; <span style=\"color:gold;\">**Probabilit√† congiunta**</span> (joint probability), perch√© √® la probabilit√† che questi due eventi accadano insieme.\n",
    "\n",
    "La regola del prodotto collega la probabilit√† congiunta con la probabilit√† condizionate, in quanto:\n",
    "\n",
    "# $P(x, y) = P(x | y) P(y)$\n",
    "\n",
    "# $P(x | y) = \\frac{P(x, y)}{P(y)}$\n",
    "\n",
    "La probabilit√† a posteriori, applicando la regola di Bayes sar√†:\n",
    "\n",
    "# $P(y | x) = \\frac{P(x | y) * P(y)}{P(x)}= \\frac{P(x, y)}{P(x)}$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density estimation the JOINT Density JD\n",
    "\n",
    "Se possiamo stimare la <span style=\"color:gold;\">**joint probability**</span> $P(X = x, Y = c)$, ovvero la probabilit√† che **X** sia uguale a **x** e che **Y** sia uguale a **c**, allora utilizzando la regola del prodotto delle probabilit√† posso trovare tutte le probabilit√† condizionate.\n",
    "\n",
    "\n",
    "Per fare density esimation posso usare una JD Table:\n",
    "\n",
    "![JD](./images/bayesLDA1.png)\n",
    "\n",
    "Tramite conteggio all'interno del mio dataset posso verificare la probabilit√† di quante volte sia presente all'interno del mio dataset una combinazione di variabili aleatorie rispetto al totale.\n",
    "\n",
    "Problemi:\n",
    "- La JD table funziona solo per le variabili numerabili (nel continuo non funziona)\n",
    "- Se le variabili possono assumere molti valori, le possibili configurazioni possono salire molto velocemente\n",
    "- Molto spesso le JD Table sono soggette a overfitting.\n",
    "\n",
    "# Overfitting\n",
    "Siccome il nostro dataset non rappresenta il fenomeno, ma una rappresentazione approssimata del vero fenomeno, pu√≤ non coprire tutti i possibili casi. Quindi costruendo la JD table su un determinato dataset potrebbe voler dire avere probabilit√† 0 per alcuni casi che invece potrebbero accadere.\n",
    "Se la mia tabella di densit√† di probabilit√† √® talmente specializzata su questo dataset, non rappresenta bene il fenomeno e quindi non √® generalizzabile.\n",
    "Molto spesso uno stimatore di densit√† di probabilit√† √® soggetto a overfitting &rarr; il mio classificatore ha visto una porzione di fenomeno troppo piccola.\n",
    "\n",
    "Al posto di stimare $P(X = x, Y = c)$, che tiene conto di tutte le possibili combinazioni, posso stimare $P(x|c)$, cio√® \"fissata la classe qual √® la probabilit√† di **x**?\n",
    "\n",
    "Bloccando la classe, l'overfitting non c'√®!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametric Maximum Likelihood Density Estimation\n",
    "\n",
    "Viene utilizzato nel caso continuo, dove definisco una determinata funzione $p(x|\\theta)$, dove $\\theta$ √® un set di parametri.\n",
    "La funzione √® nota, ad esempio una delle pi√π usate √® la gaussiana.\n",
    "\n",
    "Cerco il set di parametri \\theta che massimizza il prodotto su tutto il dataset di $p(x|\\theta)$, ovvero il prodotto della likelihood di ogni singolo elemento del dataset:\n",
    "\n",
    "# $\\hat{\\theta} = argmax_{\\theta} \\prod_{x_i \\in D} p(x_i | \\theta)$\n",
    "\n",
    "La produttoria non √® molto bella da usare perch√© quando ci sono dei numeri molto prossimi allo zero, anche tutta la quantit√† risultante tender√† a zero.\n",
    "Per evitare questo problema si usa il logaritmo, che trasforma la produttoria in una sommatoria:\n",
    "\n",
    "# $\\hat{\\theta} = argmax_{\\theta} \\sum_{x_i \\in D} log(p(x_i | \\theta))$\n",
    "\n",
    "Quando passo ai logaritmi, il logaritmo di una produttoria √® uguale alla sommatoria dei logaritmi.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-parametric Estimation\n",
    "\n",
    "Per ogni possibile valore che pu√≤ assumere una variabile, conto all'interno del dataset quanti elementi assumono quel determinato valore. Costruisco un istogramma $H(x)$ contando il numero di valori che assume la variabile **x*** e lo divido per il totale degli elementi del dataset (normalizzo).\n",
    "\n",
    "![non-parametric](./images/bayesLDA2.png)\n",
    "\n",
    "Ottengo cos√¨ una densit√† di probabilit√†\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un modello non parametrico, per costruzione pu√≤ rappresentare qualunque funzione, mentre nel modello parametrico scelgo la funzione prima.\n",
    "\n",
    "Esempio: dico che la funzione √® una gaussiana, ma se il fenomeno non √® una gaussiano perdo informazione  (se il fenomeno non √® \"a campana\").\n",
    "\n",
    "Quindi, perch√© non fare sempre una stima di densit√† non parametrica?\n",
    "Perch√© ha tre problemi:\n",
    "1. Ha un problema di maneggiabilit√† nel momento in cui il numero di valori che pu√≤ assumere ***x*** diventa molto alto\n",
    "2. Problema di overfitting che non ho con la versione parametrica perch√© nel caso io assuma che la funzione sia una gaussiana, \"interpolo\" dove non ho dati.\n",
    "3. Non so come discretizzare l'asse delle x, ovvero non so come dividere l'asse delle x in intervalli. La distribuzione potrebbe non essere uguale se vado di 5 in 5 o di 20 in 20.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuzione Gaussiana\n",
    "\n",
    "**X** variabile che segue la distribuzione gaussiana con media $\\mu$ e varianza $\\sigma^2$ &rarr; $X \\sim \\mathcal{Norm}(\\mu, \\sigma^2)$ ha funzione di densit√† di probabilit√† (ovvero la probabilit√† di ottenere un valore specifico (**x**) all'interno di quella distribuzione):\n",
    "\n",
    "# $p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimostrazione\n",
    "\n",
    "Dato un dataset **D** di **N** elementi, l'equazione della gaussiana parametrica √®:\n",
    "\n",
    "## $p(x|\\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$\n",
    "\n",
    "Dove il likelihood √®:\n",
    "\n",
    "## $L(\\mu, \\sigma^2) = \\prod_{i=1}^{N} p(x_i|\\mu, \\sigma^2) = \\prod_{i=1}^{N} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}}$\n",
    "\n",
    "Uso il logaritmo per convertire la produttoria in sommatoria (il logarimo di un prodotto √® la somma dei logaritmi):\n",
    "\n",
    "## $L(\\mu, \\sigma^2) = \\sum_{i=1}^{N} log(\\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}})$\n",
    "\n",
    "Avendo nuovamente il logaritmo di un prodotto, lo scompongo nella somma dei logaritmi:\n",
    "\n",
    "## $L(\\mu, \\sigma^2) = \\sum_{i=1}^{N} log(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}) + log(e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}})$\n",
    "\n",
    "Posso semplificare il secondo termine perch√© il logaritmo naturale di un esponenziale √® l'esponente:\n",
    "\n",
    "## $L(\\mu, \\sigma^2) = \\sum_{i=1}^{N} log(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}) - \\frac{(x_i-\\mu)^2}{2\\sigma^2}$\n",
    "\n",
    "Adesso voglio fare la derivata rispetto a $\\mu$:\n",
    "\n",
    "## $\\frac{\\partial L}{\\partial \\mu} = \\sum_{i=1}^{N} \\frac{\\partial}{\\partial \\mu} log(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}) - \\frac{\\partial}{\\partial \\mu} \\frac{(x_i-\\mu)^2}{2\\sigma^2}$\n",
    "\n",
    "Dove il primo termine si semplifica <u>perch√® non dipende da</u> $\\mu$:\n",
    "\n",
    "## $\\sum_{i=1}^{N} - \\frac{(x_i-\\mu)^2}{\\sigma^2}$\n",
    "\n",
    "E facendo la derivata del secondo termine ($a(x-b)^n$ che diventa $a n (x-b)^{n-1}$) e ponendo uguale a 0:\n",
    "\n",
    "## $\\sum_{i=1}^{N} \\frac{2(x_i-\\mu)}{2\\sigma^2} = 0$\n",
    "\n",
    "Dal momento che $\\frac{1}{\\sigma^2}$ non dipende da **x**, posso portarlo fuori dalla sommatoria:\n",
    "\n",
    "## $\\frac{1}{\\sigma^2} \\sum_{i=1}^{N} \\frac{(x_i-\\mu)}{2} = 0$\n",
    "\n",
    "Posso moltiplicare da entrambe le parti per $\\sigma^2$ e semplificare il 2:\n",
    "\n",
    "## $\\sum_{i=1}^{N} (x_i-\\mu) = 0$\n",
    "\n",
    "Spezzo la sommatoria:\n",
    "\n",
    "## $\\sum_{i=1}^{N} x_i = \\sum_{i=1}^{N} \\mu$\n",
    "\n",
    "Suppongo che il dataset **D** sia composto da **N** elementi. Se ho **N** elementi, $\\mu$ nella sommatoria lo sommo **N** volte, quindi:\n",
    "\n",
    "## $\\sum_{i=1}^{N} x_i = N \\mu$\n",
    "\n",
    "Dato che devo risolvere per $\\mu$, la porto a sinistra e ottengo la media:\n",
    "\n",
    "## $\\frac{\\sum_{i=1}^N x_i}{N} = \\mu$\n",
    "\n",
    "---\n",
    "\n",
    "![derivate](./images/derivate.png)\n",
    "\n",
    "Per $\\sigma$ √® la stessa cosa, ma devo fare la derivata rispetto a $\\sigma^2$:\n",
    "\n",
    "## $\\frac{\\partial L}{\\partial \\sigma^2}$ &rarr; $\\sum_{i=1}^{N} log(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}) - \\frac{(x_i-\\mu)^2}{2\\sigma^2}$\n",
    "\n",
    "Si ottiene:\n",
    "\n",
    "\n",
    "```\n",
    "Per l'esame saper costruire la Likelihood di una funzione\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il Parametric Maximum Likelihood risolve l'overfitting? No, perch√© non gestisce l'overfitting in alcun modo. Per prevenirlo si usa uno \n",
    "\n",
    "# Naive Density Estimator\n",
    "\n",
    "Se io ho **k** variabili aleatorie, considero ogni variabile <u>indipendente dalle altre</u>, quindi:\n",
    "\n",
    "## $P(x_1, x_2, ..., x_k | c) = \\prod_{i=1}^k P(x_i | c)$ \n",
    "\n",
    "In questo modo considero ogni variabile indipendente dalle altre, quindi non ho pi√π un problema di overfitting perch√© non dipendo pi√π dalle possibili configurazioni delle k variabili $x_1, x_2, ..., x_k$, ma semplicemente dalle configurazioni di ogni singola variabile.\n",
    "\n",
    "Perdo un po' di capacit√† di modellazione in quanto non considero i casi in cui le variabili si influenzino tra di loro.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "Il classificatore baesyano di tipo naive approssima il classificatore baesiano con la likelihood, considerando ogni variabile aleatoria indipendente dalle altre. Quindi la likelihood fattorizza come la probabilit√† del singolo attributo, data la classe:\n",
    "\n",
    "## $\\phi_c(x) = p(X = x | Y = c) = \\prod_{d=1}^k p(X_d = x_d | Y = c) = \\prod_{d=1}^k \\phi_{cd}(x_d)$\n",
    "\n",
    "La forma generale per il classificatore naive baesyano:\n",
    "\n",
    "## $f_{NB}(x) = argmax_{c \\in ùí¥}\\pi_c \\prod_{d=1}^k \\phi_{cd}(x_d)$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Conditional Distributions\n",
    "\n",
    "![CCD](./images/bayesLDA4.png)\n",
    "\n",
    "- Nel caso reale &rarr; Distribuzione Normale\n",
    "- Nel caso di valori binari &rarr; Distribuzione di Bernoulli\n",
    "  - In questo caso il parametro √® $\\theta$ mentre $x_d$ vale 0 o 1 \n",
    "- Nel caso di valori categorici, ovvero dove $x_d$ pu√≤ valere 1, 2, 3, ... *k* &rarr; Distribuzione categorica\n",
    "  - dove ho tanti $\\theta$, uno per ogni valore che pu√≤ assumere $x$, poi se $x$ assume un determinato valore espresso nelle parentesi quadre $[x_d = v]$ vale 1, altrimenti vale 0 \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussiana multivariata\n",
    "\n",
    "## $\\frac {1}{2\\pi ^{k/2}|\\Sigma |^{1/2}}e^{-{\\frac {1}{2}}({\\overline {x} }-{\\overline {\\mu }})^{\\mathrm {T} }\\Sigma ^{-1}({\\overline {x} }-{\\overline {\\mu }})}$\n",
    "\n",
    "dove $\\overline {x}$ e $\\overline {\\mu }$ sono vettori di dimensione **k** e $\\Sigma$ √® una matrice di covarianza.\n",
    "\n",
    "Se uso l'assunzione Naive, ovvero $P(x_1, x_2, ..., x_k | c) = \\prod_{i=1}^k P(x_i | c)$, la distribuzione diventa la produttoria di tante gaussiane univariate:\n",
    "\n",
    "## $\\prod_{i=1}^k \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}}$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning for Naive Bayes\n",
    "\n",
    "Il classificatore bayesiano ha due ingredienti:\n",
    "1. Probabilit√† a priori $\\pi_c$\n",
    "    - Calcolata prendendo il dataset $D$, conto quante volte $y_i = c$ diviso il totale dei possibili casi, e ottengo la probabilit√† di una classe:\n",
    "        ### $\\pi_c = \\frac{1}{N}{\\sum_{i=1}^N [(y_i = c)]}$\n",
    "2. Likelihood, che devo scegliere se farla parametrica o non parametrica:\n",
    "    -  A seconda della distribuzione che ho scelto, prendo tutte le $x$ che appartengono a una determinata classe $c_1$, quindi blocco la classe e per esempio calcolo la media e il sigma della gaussiana. Ottengo cos√¨ la Likelihood per la classe $c_1$, che poi dovr√≤ ripetere per la classe $c_2$ e cos√¨ via.\n",
    "\n",
    "![learning](./images/bayesLDA5.png)\n",
    "        \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometric Interpretation\n",
    "\n",
    "Ogni classificatore ha anche una rappresentazione geometrica. Supponiamo di essere nello spazio bidimensionale e di avere $x \\in ‚Ñù^2$ con le classi  $c_0 e c_1$. Potendo rappresentare ogni variabile $x_i$ sul piano, qualsiasi superficie che divide lo spazio cartesiano in due parti, sta classificando. \n",
    "\n",
    "Quindi un classificatore pu√≤ essere rappresentato come un confine che divide lo spazio in *n* partizioni pari al numero delle classi, chiamato <span style=\"color:gold;\">**decision boundary**</span>, che consiste in un set di punti $x$ dove (assumendo di essere nel caso naive, nel caso di una gaussiana e aggiungendo i log):\n",
    "\n",
    "\n",
    "#### $\\log(\\pi_0) + \\sum_{d=1}^D \\log(-\\frac{1}{2} \\log(2\\pi\\sigma^2_{d0})) - \\frac{1}{2\\sigma^2_{d0}} (x_d-\\mu_{d0})^2 - \\log(\\pi_1) + \\sum_{d=1}^D -\\frac{1}{2} \\log(2\\pi\\sigma^2_{d1}) - \\frac{1}{2\\sigma^2_{d1}} (x_d-\\mu_{d1})^2 = 0$\n",
    "\n",
    "Dato che a me interessa valutare in funzione di $x$, siccome $\\log(-\\frac{1}{2} \\log(2\\pi\\sigma^2_{d0}))$ e $\\log(2\\pi\\sigma^2_{d1})$ non dipendono da $x$, posso chiamarli rispettivamente $a$ e $b$.\n",
    "\n",
    "Il secondi termini $\\frac{1}{2\\sigma^2_{d0}} (x_d-\\mu_{d0})^2$ e $\\frac{1}{2\\sigma^2_{d1}} (x_d-\\mu_{d1})^2$ dipendono da $x$, e svolgendo i quadrati ottengo qualcosa nella forma:\n",
    "\n",
    "### $$\\sum_{d=1}^D (a_d x_d^2 + b_d x_d) + c_d = 0$$\n",
    "\n",
    "Essendo una funzione quadratica di $x$, la partizione del piano non √® fatta da una retta, bens√¨ da una curva.\n",
    "***Quindi in generale, un classificatore bayesiano, con una gaussiana come likelihood function partiziona il piano con parabole o con iperboli***\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vantaggi e svantaggi\n",
    "\n",
    "- In termine di velocit√†, il classificatore bayesiano √® molto veloce sia per apprendimento che inferenza. L'apprendimento applico la formula della maximum likelihood (nel caso della gaussiana ci si mette poco) e ha un carico computazione basso.\n",
    "- In termini di parametri devo mantenere $D$ parametri della mia funzione parametrica che sto scegliendo per ogni classe $C$ o dimensioni considerate.\n",
    "Nel caso di una gaussiana devo salvarmi $D$ volte $\\mu$ e $D$ volte $\\sigma^2$ per ogni classe.\n",
    "- √à molto interpretabile perch√© posso guardare quanto una precisa variabile nella produttoria ha contribuito alla classe.\n",
    "- Per fare un classificatore bayesiano faccio una assunzione di tipo naive sulle variabili, che spesso non √® vera. Questo errore viene pagato in termini di accuratezza.\n",
    "- Ha anche il vantaggio di fare una stima anche in presenza di pochi dati\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
