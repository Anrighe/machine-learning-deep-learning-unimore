{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Error Rate\n",
    "\n",
    "Dato un dataset di esempio $D = {(x_i, y_i), i = 1 : N}$ e una funzione $f : ‚Ñù^D$ &rarr; $Y$, la Classification Error Rate √® l'<u>errore medio su **N** elementi</u> di $f$ su $D$ (conto quante volte sbaglio), ed √® definito come:\n",
    "\n",
    "# $Err(f, D) = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{ùïÄ}_{(y_i \\neq f(x_i))}$\n",
    "\n",
    "- $f(x_i)$ √® la classe predetta\n",
    "- $y_i$ √® la classe reale di appartenenza\n",
    "- ùïÄ √® la funzione indicatrice, che vale 1 se la condizione √® vera, 0 altrimenti.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Accuracy Rate\n",
    "\n",
    "Dato un dataset di esempio $D = {(x_i, y_i), i = 1 : N}$ e una funzione $f : ‚Ñù^D$ &rarr; $Y$, la Classification Accuracy Rate <u>misura della media di quante volte ci prendo</u>:\n",
    "\n",
    "# $Acc(f, D) = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{ùïÄ}_{(y_i = f(x_i))}$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior Probability\n",
    "\n",
    "Se supponiamo che la funzione **f** precedentemente menzionata sia una funzione che fornisce in output una probabilit√†, allora stiamo usando un classificatore probabilistico.\n",
    "\n",
    "Supponiamo che la probabilit√† di vedere un elemento che appartiene a una certa classe **c** sia $P(Y = c)$, dove quello dentro alle parentesi, $Y = c$, √® l'evento che stiamo considerando, ovvero che l'elemento appartenga alla classe **c**. Questa probabilit√† si indica con la notazione:\n",
    "\n",
    "# $P(Y = c) = \\pi_c$\n",
    "\n",
    "E normalmente si chiama <span style=\"color:gold;\">**prior probability**</span> (o probabilit√† a priori), perch√© di fatto non dipende da nessun elemento del dataset, ma √® una probabilit√† che viene assegnata a priori, prima di vedere il dataset (ad esempio probabilit√† a priori di capire se una persona √® maschio o femmina prima di guardarla in faccia).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood\n",
    "\n",
    "Viene definita come <span style=\"color:gold;\">likelyhood</span> la densit√† di probabilit√† di vedere un vettore $x \\in ‚Ñù^D$ che appartiene alla classe **c** come:\n",
    "\n",
    "# $p(X = x | Y = c) = \\phi_c(x)$\n",
    "\n",
    "- ***p*** (probabilit√†) in questo caso √® una densit√†, quindi √® minuscola\n",
    "    - La densit√† √® una funzione il cui integrale fa 1, mentre la probabilit√† √® gi√† l'integrale della densit√†\n",
    "\n",
    "Fissata la classe **c**, qual √® la probabilit√† che **X** sia uguale a **x**.\n",
    "La likelyhood misura quanto, fissata la classe, quello che sto guardando √® coerente con la mia classe.\n",
    "\n",
    "*Esempio*: fisso la classe maschio, guardo la foto di una persona con la barba e ottengo (presumibilmente) una probabilit√† alta di essere maschio.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A-posteriori probability\n",
    "\n",
    "Per computare la probabilit√† che un elemento appartenga a una certa classe, si usa il <span style=\"color:gold;\">**teorema di Bayes**</span>:\n",
    "\n",
    "# $P(Y = c | X = x) = \\frac{P(X = x | Y = c) P(Y = c)}{\\sum_{c' \\in ùí¥}P(X = x, Y = c')} = \\frac{\\phi_c(x) \\pi_c}{\\sum_{c' \\in ùí¥}\\phi_{c'}(x) \\pi_{c'}}$\n",
    "\n",
    "Dove la probabilit√† di che **Y** appartenga alla classe **c** dato **X** uguale a **x** √® uguale alla:\n",
    "\n",
    "# $\\frac{{\\text{ likelyhood }} * {\\text{ prior probability }}}{\\text{normalizing constant}}$\n",
    "\n",
    "dove la ***normalizing constant*** √® la sommatoria di tutti i possibili valori che pu√≤ assumere **Y** (ovvero tutte le classi possibili), quindi la somma delle quantit√† che si hanno sopra per tutte le classi.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification strategies\n",
    "\n",
    "Quando dobbiamo classificare, possiamo approcciare il problema in due modi. \n",
    "\n",
    "Supponendo di avere un dataset $D = (x_i, y_i)_{i=1..N}$ con $x_i$ vettore di feature e $y_i$ la classe, con in totale **k** classi $c_i | i = 1..k$ e un generico test sample $\\hat{x}$:\n",
    "- ### Maximum Likelihood Classification:\n",
    "  - Dal dataset **D** impara una funzione di likelyhood per ogni classe $c_i$ $P(x | c_i)$\n",
    "  - Poi prendo $\\hat{x}$ e lo passo a tutte le funzioni di likelyhood &rarr; $P(\\hat{x} | c_i)$\n",
    "  - Quella che mi d√† il valore pi√π alto sar√† la classe da attribuire a $\\hat{x}$ &rarr; $\\hat{c} = argmax_c P(\\hat{x}|c)$\n",
    "    - Sto cercando la classe che massimizza il likelihood\n",
    "  \n",
    "- ### Maximum A-Posteriori Classification:\n",
    "  - Dal dataset **D** impara una funzione di likelyhood per ogni classe $c_i$ $P(x | c_i)$\n",
    "  - Da **D** imparo anche la probabilit√† a priori per ogni calsse $c_i$ $P(c_i)$\n",
    "  - dato $\\hat{x}$ applico la regola di Bayes per ottenere $P(c_i | \\hat{x})$\n",
    "  - $\\hat{c} = argmax_c P(c_i | \\hat{x})$\n",
    "    - Sto cercando la classe che massimizza\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Bayes Optimal Classifier\n",
    "\n",
    "## $f_B(x) = argmax_{c \\in ùí¥} P(Y = c | X = x) = argmax_{c \\in ùí¥} \\phi_c(x) \\pi_c$\n",
    "\n",
    "Da un punto di vista teorico, il classificatore baesyano minimizza indirettamente l'errore, perch√© assegno sempre l'errore che ha pi√π probabilit√† di essere giusta, ma non √® utilizzabile nella pratica perch√© X=x non √® finita e perch√© dipende dalle funzioni che ha imparato il classificatore (che potrebbero essere sbaliate in quanto potrebbe aver appreso un fenomeno non correttamente).\n",
    "\n",
    "Quindi tra tutti i possibili errori attesi, il classificatore baesyano mi fornisce il pi√π basso.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prodotto di probabilit√†\n",
    "Se ho due variabili aleatorie **x**, **y**, la probabilit√† congiunta √® espressa come $P(x, y)$.\n",
    "\n",
    "Se la voglio valutare in un caso specifico sar√† $P(x=\\hat{x}, y=\\hat{y})$, dove **x** e **y** sono i nomi delle variabili e $\\hat{x}$ e $\\hat{y}$ sono due osservazioni &rarr; <span style=\"color:gold;\">**Probabilit√† congiunta**</span> (joint probability), perch√© √® la probabilit√† che questi due eventi accadano insieme.\n",
    "\n",
    "La regola del prodotto collega la probabilit√† congiunta con la probabilit√† condizionate, in quanto:\n",
    "\n",
    "# $P(x, y) = P(x | y) P(y)$\n",
    "\n",
    "# $P(x | y) = \\frac{P(x, y)}{P(y)}$\n",
    "\n",
    "La probabilit√† a posteriori, applicando la regola di Bayes sar√†:\n",
    "\n",
    "# $P(y | x) = \\frac{P(x | y) * P(y)}{P(x)}= \\frac{P(x, y)}{P(x)}$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density estimation the JOINT Density JD\n",
    "\n",
    "Se possiamo stimare la <span style=\"color:gold;\">**joint probability**</span> $P(X = x, Y = c)$, ovvero la probabilit√† che **X** sia uguale a **x** e che **Y** sia uguale a **c**, allora utilizzando la regola del prodotto delle probabilit√† posso trovare tutte le probabilit√† condizionate.\n",
    "\n",
    "\n",
    "Per fare density esimation posso usare una JD Table:\n",
    "\n",
    "![JD](./images/bayesLDA1.png)\n",
    "\n",
    "Tramite conteggio all'interno del mio dataset posso verificare la probabilit√† di quante volte sia presente all'interno del mio dataset una combinazione di variabili aleatorie rispetto al totale.\n",
    "\n",
    "Problemi:\n",
    "- La JD table funziona solo per le variabili numerabili (nel continuo non funziona)\n",
    "- Se le variabili possono assumere molti valori, le possibili configurazioni possono salire molto velocemente\n",
    "- Molto spesso le JD Table sono soggette a overfitting.\n",
    "\n",
    "# Overfitting\n",
    "Siccome il nostro dataset non rappresenta il fenomeno, ma una rappresentazione approssimata del vero fenomeno, pu√≤ non coprire tutti i possibili casi. Quindi costruendo la JD table su un determinato dataset potrebbe voler dire avere probabilit√† 0 per alcuni casi che invece potrebbero accadere.\n",
    "Se la mia tabella di densit√† di probabilit√† √® talmente specializzata su questo dataset, non rappresenta bene il fenomeno e quindi non √® generalizzabile.\n",
    "Molto spesso uno stimatore di densit√† di probabilit√† √® soggetto a overfitting &rarr; il mio classificatore ha visto una porzione di fenomeno troppo piccola.\n",
    "\n",
    "Al posto di stimare $P(X = x, Y = c)$, che tiene conto di tutte le possibili combinazioni, posso stimare $P(x|c)$, cio√® \"fissata la classe qual √® la probabilit√† di **x**?\n",
    "\n",
    "Bloccando la classe, l'overfitting non c'√®!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametric Maximum Likelihood Density Estimation\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
