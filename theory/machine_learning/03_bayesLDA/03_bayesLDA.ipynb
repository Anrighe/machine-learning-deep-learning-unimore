{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Error Rate\n",
    "\n",
    "Dato un dataset di esempio $D = {(x_i, y_i), i = 1 : N}$ e una funzione $f : ‚Ñù^D$ &rarr; $Y$, la Classification Error Rate √® l'<u>errore medio su **N** elementi</u> di $f$ su $D$ (conto quante volte sbaglio), ed √® definito come:\n",
    "\n",
    "# $Err(f, D) = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{ùïÄ}_{(y_i \\neq f(x_i))}$\n",
    "\n",
    "- $f(x_i)$ √® la classe predetta\n",
    "- $y_i$ √® la classe reale di appartenenza\n",
    "- ùïÄ √® la funzione indicatrice, che vale 1 se la condizione √® vera, 0 altrimenti.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Accuracy Rate\n",
    "\n",
    "Dato un dataset di esempio $D = {(x_i, y_i), i = 1 : N}$ e una funzione $f : ‚Ñù^D$ &rarr; $Y$, la Classification Accuracy Rate <u>misura della media di quante volte ci prendo</u>:\n",
    "\n",
    "# $Acc(f, D) = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{ùïÄ}_{(y_i = f(x_i))}$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior Probability\n",
    "\n",
    "Se supponiamo che la funzione **f** precedentemente menzionata sia una funzione che fornisce in output una probabilit√†, allora stiamo usando un classificatore probabilistico.\n",
    "\n",
    "Supponiamo che la probabilit√† di vedere un elemento che appartiene a una certa classe **c** sia $P(Y = c)$, dove quello dentro alle parentesi, $Y = c$, √® l'evento che stiamo considerando, ovvero che l'elemento appartenga alla classe **c**. Questa probabilit√† si indica con la notazione:\n",
    "\n",
    "# $P(Y = c) = \\pi_c$\n",
    "\n",
    "E normalmente si chiama <span style=\"color:gold;\">**prior probability**</span> (o probabilit√† a priori), perch√© di fatto non dipende da nessun elemento del dataset, ma √® una probabilit√† che viene assegnata a priori, prima di vedere il dataset (ad esempio probabilit√† a priori di capire se una persona √® maschio o femmina prima di guardarla in faccia).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood\n",
    "\n",
    "Viene definita come <span style=\"color:gold;\">likelyhood</span> la densit√† di probabilit√† di vedere un vettore $x \\in ‚Ñù^D$ che appartiene alla classe **c** come:\n",
    "\n",
    "# $p(X = x | Y = c) = \\phi_c(x)$\n",
    "\n",
    "- ***p*** (probabilit√†) in questo caso √® una densit√†, quindi √® minuscola\n",
    "    - La densit√† √® una funzione il cui integrale fa 1, mentre la probabilit√† √® gi√† l'integrale della densit√†\n",
    "\n",
    "Fissata la classe **c**, qual √® la probabilit√† che **X** sia uguale a **x**.\n",
    "La likelyhood misura quanto, fissata la classe, quello che sto guardando √® coerente con la mia classe.\n",
    "\n",
    "*Esempio*: fisso la classe maschio, guardo la foto di una persona con la barba e ottengo (presumibilmente) una probabilit√† alta di essere maschio.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A-posteriori probability\n",
    "\n",
    "Per computare la probabilit√† che un elemento appartenga a una certa classe, si usa il <span style=\"color:gold;\">**teorema di Bayes**</span>:\n",
    "\n",
    "# $P(Y = c | X = x) = \\frac{P(X = x | Y = c) P(Y = c)}{\\sum_{c' \\in ùí¥}P(X = x, Y = c')} = \\frac{\\phi_c(x) \\pi_c}{\\sum_{c' \\in ùí¥}\\phi_{c'}(x) \\pi_{c'}}$\n",
    "\n",
    "Dove la probabilit√† di che **Y** appartenga alla classe **c** dato **X** uguale a **x** √® uguale alla:\n",
    "\n",
    "# $\\frac{{\\text{ likelihood }} * {\\text{ prior probability }}}{\\text{normalizing constant}}$\n",
    "\n",
    "dove la ***normalizing constant*** √® la sommatoria di tutti i possibili valori che pu√≤ assumere **Y** (ovvero tutte le classi possibili), quindi la somma delle quantit√† che si hanno sopra per tutte le classi.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification strategies\n",
    "\n",
    "Quando dobbiamo classificare, possiamo approcciare il problema in due modi. \n",
    "\n",
    "Supponendo di avere un dataset $D = (x_i, y_i)_{i=1..N}$ con $x_i$ vettore di feature e $y_i$ la classe, con in totale **k** classi $c_i | i = 1..k$ e un generico test sample $\\hat{x}$:\n",
    "- ### Maximum Likelihood Classification:\n",
    "  - Dal dataset **D** impara una funzione di likelyhood per ogni classe $c_i$ $P(x | c_i)$\n",
    "  - Poi prendo $\\hat{x}$ e lo passo a tutte le funzioni di likelyhood &rarr; $P(\\hat{x} | c_i)$\n",
    "  - Quella che mi d√† il valore pi√π alto sar√† la classe da attribuire a $\\hat{x}$ &rarr; $\\hat{c} = argmax_c P(\\hat{x}|c)$\n",
    "    - Sto cercando la classe che massimizza il likelihood\n",
    "  \n",
    "- ### Maximum A-Posteriori Classification:\n",
    "  - Dal dataset **D** impara una funzione di likelyhood per ogni classe $c_i$ $P(x | c_i)$\n",
    "  - Da **D** imparo anche la probabilit√† a priori per ogni calsse $c_i$ $P(c_i)$\n",
    "  - dato $\\hat{x}$ applico la regola di Bayes per ottenere $P(c_i | \\hat{x})$\n",
    "  - $\\hat{c} = argmax_c P(c_i | \\hat{x})$\n",
    "    - Sto cercando la classe che massimizza\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Bayes Optimal Classifier\n",
    "\n",
    "## $f_B(x) = argmax_{c \\in ùí¥} P(Y = c | X = x) = argmax_{c \\in ùí¥} \\phi_c(x) \\pi_c$\n",
    "\n",
    "Da un punto di vista teorico, il classificatore baesyano minimizza indirettamente l'errore, perch√© assegno sempre l'errore che ha pi√π probabilit√† di essere giusta, ma non √® utilizzabile nella pratica perch√© X=x non √® finita e perch√© dipende dalle funzioni che ha imparato il classificatore (che potrebbero essere sbaliate in quanto potrebbe aver appreso un fenomeno non correttamente).\n",
    "\n",
    "Quindi tra tutti i possibili errori attesi, il classificatore baesyano mi fornisce il pi√π basso.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prodotto di probabilit√†\n",
    "Se ho due variabili aleatorie **x**, **y**, la probabilit√† congiunta √® espressa come $P(x, y)$.\n",
    "\n",
    "Se la voglio valutare in un caso specifico sar√† $P(x=\\hat{x}, y=\\hat{y})$, dove **x** e **y** sono i nomi delle variabili e $\\hat{x}$ e $\\hat{y}$ sono due osservazioni &rarr; <span style=\"color:gold;\">**Probabilit√† congiunta**</span> (joint probability), perch√© √® la probabilit√† che questi due eventi accadano insieme.\n",
    "\n",
    "La regola del prodotto collega la probabilit√† congiunta con la probabilit√† condizionate, in quanto:\n",
    "\n",
    "# $P(x, y) = P(x | y) P(y)$\n",
    "\n",
    "# $P(x | y) = \\frac{P(x, y)}{P(y)}$\n",
    "\n",
    "La probabilit√† a posteriori, applicando la regola di Bayes sar√†:\n",
    "\n",
    "# $P(y | x) = \\frac{P(x | y) * P(y)}{P(x)}= \\frac{P(x, y)}{P(x)}$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density estimation the JOINT Density JD\n",
    "\n",
    "Se possiamo stimare la <span style=\"color:gold;\">**joint probability**</span> $P(X = x, Y = c)$, ovvero la probabilit√† che **X** sia uguale a **x** e che **Y** sia uguale a **c**, allora utilizzando la regola del prodotto delle probabilit√† posso trovare tutte le probabilit√† condizionate.\n",
    "\n",
    "\n",
    "Per fare density esimation posso usare una JD Table:\n",
    "\n",
    "![JD](./images/bayesLDA1.png)\n",
    "\n",
    "Tramite conteggio all'interno del mio dataset posso verificare la probabilit√† di quante volte sia presente all'interno del mio dataset una combinazione di variabili aleatorie rispetto al totale.\n",
    "\n",
    "Problemi:\n",
    "- La JD table funziona solo per le variabili numerabili (nel continuo non funziona)\n",
    "- Se le variabili possono assumere molti valori, le possibili configurazioni possono salire molto velocemente\n",
    "- Molto spesso le JD Table sono soggette a overfitting.\n",
    "\n",
    "# Overfitting\n",
    "Siccome il nostro dataset non rappresenta il fenomeno, ma una rappresentazione approssimata del vero fenomeno, pu√≤ non coprire tutti i possibili casi. Quindi costruendo la JD table su un determinato dataset potrebbe voler dire avere probabilit√† 0 per alcuni casi che invece potrebbero accadere.\n",
    "Se la mia tabella di densit√† di probabilit√† √® talmente specializzata su questo dataset, non rappresenta bene il fenomeno e quindi non √® generalizzabile.\n",
    "Molto spesso uno stimatore di densit√† di probabilit√† √® soggetto a overfitting &rarr; il mio classificatore ha visto una porzione di fenomeno troppo piccola.\n",
    "\n",
    "Al posto di stimare $P(X = x, Y = c)$, che tiene conto di tutte le possibili combinazioni, posso stimare $P(x|c)$, cio√® \"fissata la classe qual √® la probabilit√† di **x**?\n",
    "\n",
    "Bloccando la classe, l'overfitting non c'√®!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametric Maximum Likelihood Density Estimation\n",
    "\n",
    "Viene utilizzato nel caso continuo, dove definisco una determinata funzione $p(x|\\theta)$, dove $\\theta$ √® un set di parametri.\n",
    "La funzione √® nota, ad esempio una delle pi√π usate √® la gaussiana.\n",
    "\n",
    "Cerco il set di parametri \\theta che massimizza il prodotto su tutto il dataset di $p(x|\\theta)$, ovvero il prodotto della likelihood di ogni singolo elemento del dataset:\n",
    "\n",
    "# $\\hat{\\theta} = argmax_{\\theta} \\prod_{x_i \\in D} p(x_i | \\theta)$\n",
    "\n",
    "La produttoria non √® molto bella da usare perch√© quando ci sono dei numeri molto prossimi allo zero, anche tutta la quantit√† risultante tender√† a zero.\n",
    "Per evitare questo problema si usa il logaritmo, che trasforma la produttoria in una sommatoria:\n",
    "\n",
    "# $\\hat{\\theta} = argmax_{\\theta} \\sum_{x_i \\in D} log(p(x_i | \\theta))$\n",
    "\n",
    "Quando passo ai logaritmi, il logaritmo di una produttoria √® uguale alla sommatoria dei logaritmi.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-parametric Estimation\n",
    "\n",
    "Per ogni possibile valore che pu√≤ assumere una variabile, conto all'interno del dataset quanti elementi assumono quel determinato valore. Costruisco un istogramma $H(x)$ contando il numero di valori che assume la variabile **x*** e lo divido per il totale degli elementi del dataset (normalizzo).\n",
    "\n",
    "![non-parametric](./images/bayesLDA2.png)\n",
    "\n",
    "Ottengo cos√¨ una densit√† di probabilit√†\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un modello non parametrico, per costruzione pu√≤ rappresentare qualunque funzione, mentre nel modello parametrico scelgo la funzione prima.\n",
    "\n",
    "Esempio: dico che la funzione √® una gaussiana, ma se il fenomeno non √® una gaussiano perdo informazione  (se il fenomeno non √® \"a campana\").\n",
    "\n",
    "Quindi, perch√© non fare sempre una stima di densit√† non parametrica?\n",
    "Perch√© ha tre problemi:\n",
    "1. Ha un problema di maneggiabilit√† nel momento in cui il numero di valori che pu√≤ assumere ***x*** diventa molto alto\n",
    "2. Problema di overfitting che non ho con la versione parametrica perch√© nel caso io assuma che la funzione sia una gaussiana, \"interpolo\" dove non ho dati.\n",
    "3. Non so come discretizzare l'asse delle x, ovvero non so come dividere l'asse delle x in intervalli. La distribuzione potrebbe non essere uguale se vado di 5 in 5 o di 20 in 20.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuzione Gaussiana\n",
    "\n",
    "**X** variabile che segue la distribuzione gaussiana con media $\\mu$ e varianza $\\sigma^2$ &rarr; $X \\sim \\mathcal{Norm}(\\mu, \\sigma^2)$ ha funzione di densit√† di probabilit√† (ovvero la probabilit√† di ottenere un valore specifico (**x**) all'interno di quella distribuzione):\n",
    "\n",
    "# $p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimostrazione\n",
    "\n",
    "Dato un dataset **D** di **N** elementi, l'equazione della gaussiana parametrica √®:\n",
    "\n",
    "## $p(x|\\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$\n",
    "\n",
    "Dove il likelihood √®:\n",
    "\n",
    "## $L(\\mu, \\sigma^2) = \\prod_{i=1}^{N} p(x_i|\\mu, \\sigma^2) = \\prod_{i=1}^{N} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}}$\n",
    "\n",
    "Uso il logaritmo per convertire la produttoria in sommatoria (il logarimo di un prodotto √® la somma dei logaritmi):\n",
    "\n",
    "## $L(\\mu, \\sigma^2) = \\sum_{i=1}^{N} log(\\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}})$\n",
    "\n",
    "Avendo nuovamente il logaritmo di un prodotto, lo scompongo nella somma dei logaritmi:\n",
    "\n",
    "## $L(\\mu, \\sigma^2) = \\sum_{i=1}^{N} log(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}) + log(e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}})$\n",
    "\n",
    "Posso semplificare il secondo termine perch√© il logaritmo naturale di un esponenziale √® l'esponente:\n",
    "\n",
    "## $L(\\mu, \\sigma^2) = \\sum_{i=1}^{N} log(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}) - \\frac{(x_i-\\mu)^2}{2\\sigma^2}$\n",
    "\n",
    "Adesso voglio fare la derivata rispetto a $\\mu$:\n",
    "\n",
    "## $\\frac{\\partial L}{\\partial \\mu} = \\sum_{i=1}^{N} \\frac{\\partial}{\\partial \\mu} log(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}) - \\frac{\\partial}{\\partial \\mu} \\frac{(x_i-\\mu)^2}{2\\sigma^2}$\n",
    "\n",
    "Dove il primo termine si semplifica <u>perch√® non dipende da</u> $\\mu$:\n",
    "\n",
    "## $\\sum_{i=1}^{N} - \\frac{(x_i-\\mu)^2}{\\sigma^2}$\n",
    "\n",
    "E facendo la derivata del secondo termine ($a(x-b)^n$ che diventa $a n (x-b)^{n-1}$) e ponendo uguale a 0:\n",
    "\n",
    "## $\\sum_{i=1}^{N} \\frac{2(x_i-\\mu)}{2\\sigma^2} = 0$\n",
    "\n",
    "Dal momento che $\\frac{1}{\\sigma^2}$ non dipende da **x**, posso portarlo fuori dalla sommatoria:\n",
    "\n",
    "## $\\frac{1}{\\sigma^2} \\sum_{i=1}^{N} \\frac{(x_i-\\mu)}{2} = 0$\n",
    "\n",
    "Posso moltiplicare da entrambe le parti per $\\sigma^2$ e semplificare il 2:\n",
    "\n",
    "## $\\sum_{i=1}^{N} (x_i-\\mu) = 0$\n",
    "\n",
    "Spezzo la sommatoria:\n",
    "\n",
    "## $\\sum_{i=1}^{N} x_i = \\sum_{i=1}^{N} \\mu$\n",
    "\n",
    "Suppongo che il dataset **D** sia composto da **N** elementi. Se ho **N** elementi, $\\mu$ nella sommatoria lo sommo **N** volte, quindi:\n",
    "\n",
    "## $\\sum_{i=1}^{N} x_i = N \\mu$\n",
    "\n",
    "Dato che devo risolvere per $\\mu$, la porto a sinistra e ottengo la media:\n",
    "\n",
    "## $\\frac{\\sum_{i=1}^N x_i}{N} = \\mu$\n",
    "\n",
    "---\n",
    "\n",
    "![derivate](./images/derivate.png)\n",
    "\n",
    "Per $\\sigma$ √® la stessa cosa, ma devo fare la derivata rispetto a $\\sigma^2$:\n",
    "\n",
    "## $\\frac{\\partial L}{\\partial \\sigma^2}$ &rarr; $\\sum_{i=1}^{N} log(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}) - \\frac{(x_i-\\mu)^2}{2\\sigma^2}$\n",
    "\n",
    "Si ottiene:\n",
    "\n",
    "\n",
    "```\n",
    "Per l'esame saper costruire la Likelihood di una funzione\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il Parametric Maximum Likelihood risolve l'overfitting? No, perch√© non gestisce l'overfitting in alcun modo. Per prevenirlo si usa uno \n",
    "\n",
    "# Naive Density Estimator\n",
    "\n",
    "Se io ho **k** variabili aleatorie, considero ogni variabile <u>indipendente dalle altre</u>, quindi:\n",
    "\n",
    "## $P(x_1, x_2, ..., x_k | c) = \\prod_{i=1}^k P(x_i | c)$ \n",
    "\n",
    "In questo modo considero ogni variabile indipendente dalle altre, quindi non ho pi√π un problema di overfitting perch√© non dipendo pi√π dalle possibili configurazioni delle k variabili $x_1, x_2, ..., x_k$, ma semplicemente dalle configurazioni di ogni singola variabile.\n",
    "\n",
    "Perdo un po' di capacit√† di modellazione in quanto non considero i casi in cui le variabili si influenzino tra di loro.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "Il classificatore baesyano di tipo naive approssima il classificatore baesiano con la likelihood, considerando ogni variabile aleatoria indipendente dalle altre. Quindi la likelihood fattorizza come la probabilit√† del singolo attributo, data la classe:\n",
    "\n",
    "## $\\phi_c(x) = p(X = x | Y = c) = \\prod_{d=1}^k p(X_d = x_d | Y = c) = \\prod_{d=1}^k \\phi_{cd}(x_d)$\n",
    "\n",
    "La forma generale per il classificatore naive baesyano:\n",
    "\n",
    "## $f_{NB}(x) = argmax_{c \\in ùí¥}\\pi_c \\prod_{d=1}^k \\phi_{cd}(x_d)$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Conditional Distributions\n",
    "\n",
    "![CCD](./images/bayesLDA4.png)\n",
    "\n",
    "- Nel caso reale &rarr; Distribuzione Normale\n",
    "- Nel caso di valori binari &rarr; Distribuzione di Bernoulli\n",
    "  - In questo caso il parametro √® $\\theta$ mentre $x_d$ vale 0 o 1 \n",
    "- Nel caso di valori categorici, ovvero dove $x_d$ pu√≤ valere 1, 2, 3, ... *k* &rarr; Distribuzione categorica\n",
    "  - dove ho tanti $\\theta$, uno per ogni valore che pu√≤ assumere $x$, poi se $x$ assume un determinato valore espresso nelle parentesi quadre $[x_d = v]$ vale 1, altrimenti vale 0 \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussiana multivariata\n",
    "\n",
    "## $\\frac {1}{2\\pi ^{k/2}|\\Sigma |^{1/2}}e^{-{\\frac {1}{2}}({\\overline {x} }-{\\overline {\\mu }})^{\\mathrm {T} }\\Sigma ^{-1}({\\overline {x} }-{\\overline {\\mu }})}$\n",
    "\n",
    "dove $\\overline {x}$ e $\\overline {\\mu }$ sono vettori di dimensione **k** e $\\Sigma$ √® una matrice di covarianza.\n",
    "\n",
    "Se uso l'assunzione Naive, ovvero $P(x_1, x_2, ..., x_k | c) = \\prod_{i=1}^k P(x_i | c)$, la distribuzione diventa la produttoria di tante gaussiane univariate:\n",
    "\n",
    "## $\\prod_{i=1}^k \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}}$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning for Naive Bayes\n",
    "\n",
    "Il classificatore bayesiano ha due ingredienti:\n",
    "1. Probabilit√† a priori $\\pi_c$\n",
    "    - Calcolata prendendo il dataset $D$, conto quante volte $y_i = c$ diviso il totale dei possibili casi, e ottengo la probabilit√† di una classe:\n",
    "        ### $\\pi_c = \\frac{1}{N}{\\sum_{i=1}^N [(y_i = c)]}$\n",
    "2. Likelihood, che devo scegliere se farla parametrica o non parametrica:\n",
    "    -  A seconda della distribuzione che ho scelto, prendo tutte le $x$ che appartengono a una determinata classe $c_1$, quindi blocco la classe e per esempio calcolo la media e il sigma della gaussiana. Ottengo cos√¨ la Likelihood per la classe $c_1$, che poi dovr√≤ ripetere per la classe $c_2$ e cos√¨ via.\n",
    "\n",
    "![learning](./images/bayesLDA5.png)\n",
    "        \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometric Interpretation\n",
    "\n",
    "Ogni classificatore ha anche una rappresentazione geometrica. Supponiamo di essere nello spazio bidimensionale e di avere $x \\in ‚Ñù^2$ con le classi  $c_0 e c_1$. Potendo rappresentare ogni variabile $x_i$ sul piano, qualsiasi superficie che divide lo spazio cartesiano in due parti, sta classificando. \n",
    "\n",
    "Quindi un classificatore pu√≤ essere rappresentato come un confine che divide lo spazio in *n* partizioni pari al numero delle classi, chiamato <span style=\"color:gold;\">**decision boundary**</span>, che consiste in un set di punti $x$ dove (assumendo di essere nel caso naive, nel caso di una gaussiana e aggiungendo i log):\n",
    "\n",
    "\n",
    "#### $\\log(\\pi_0) + \\sum_{d=1}^D \\log(-\\frac{1}{2} \\log(2\\pi\\sigma^2_{d0})) - \\frac{1}{2\\sigma^2_{d0}} (x_d-\\mu_{d0})^2 - \\log(\\pi_1) + \\sum_{d=1}^D -\\frac{1}{2} \\log(2\\pi\\sigma^2_{d1}) - \\frac{1}{2\\sigma^2_{d1}} (x_d-\\mu_{d1})^2 = 0$\n",
    "\n",
    "Dato che a me interessa valutare in funzione di $x$, siccome $\\log(-\\frac{1}{2} \\log(2\\pi\\sigma^2_{d0}))$ e $\\log(2\\pi\\sigma^2_{d1})$ non dipendono da $x$, posso chiamarli rispettivamente $a$ e $b$.\n",
    "\n",
    "Il secondi termini $\\frac{1}{2\\sigma^2_{d0}} (x_d-\\mu_{d0})^2$ e $\\frac{1}{2\\sigma^2_{d1}} (x_d-\\mu_{d1})^2$ dipendono da $x$, e svolgendo i quadrati ottengo qualcosa nella forma:\n",
    "\n",
    "### $$\\sum_{d=1}^D (a_d x_d^2 + b_d x_d) + c_d = 0$$\n",
    "\n",
    "Essendo una funzione quadratica di $x$, la partizione del piano non √® fatta da una retta, bens√¨ da una curva.\n",
    "***Quindi in generale, un classificatore bayesiano, con una gaussiana come likelihood function partiziona il piano con parabole o con iperboli***\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vantaggi e svantaggi\n",
    "\n",
    "- In termine di velocit√†, il classificatore bayesiano √® molto veloce sia per apprendimento che inferenza. L'apprendimento applico la formula della maximum likelihood (nel caso della gaussiana ci si mette poco) e ha un carico computazione basso.\n",
    "- In termini di parametri devo mantenere $D$ parametri della mia funzione parametrica che sto scegliendo per ogni classe $C$ o dimensioni considerate.\n",
    "Nel caso di una gaussiana devo salvarmi $D$ volte $\\mu$ e $D$ volte $\\sigma^2$ per ogni classe.\n",
    "- √à molto interpretabile perch√© posso guardare quanto una precisa variabile nella produttoria ha contribuito alla classe.\n",
    "- Per fare un classificatore bayesiano faccio una assunzione di tipo naive sulle variabili, che spesso non √® vera. Questo errore viene pagato in termini di accuratezza.\n",
    "- Ha anche il vantaggio di fare una stima anche in presenza di pochi dati\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrice di covarianza\n",
    "La matrice di covarianza √® una misura statistica utilizzata per comprendere le relazioni tra le diverse variabili in un insieme di dati multivariato. Fornisce informazioni sulla variazione congiunta tra le variabili e pu√≤ essere utile per identificare se esistono correlazioni o tendenze nei dati.\n",
    "\n",
    "La matrice di covarianza di un insieme di dati √® una matrice quadrata che contiene le covarianze tra tutte le possibili coppie di variabili nel dataset. La covarianza tra due variabili misura come variano insieme: se tendono a aumentare o diminuire contemporaneamente (covarianza positiva) o se una aumenta mentre l'altra diminuisce (covarianza negativa), o se non vi √® una correlazione evidente (covarianza vicina a zero).\n",
    "\n",
    "La matrice di covarianza √® spesso indicata come Œ£ (sigma) e ha la seguente forma generale per un dataset con n variabili:\n",
    "\n",
    "Œ£ = \n",
    "\n",
    "[$cov(X_1, X_1)$  $cov(X_1, X_2)$  ...  $cov(X_1, X_n)$      \n",
    "\n",
    "$cov(X_2, X_1)$  $cov(X_2, X_2)$  ...  $cov(X_2, X_n)$        \n",
    "\n",
    "      ...      ...       ...        ...        \n",
    "\n",
    "$cov(X_n, X_1)$  $cov(X_n, X_2)$  ...  $cov(X_n, X_n)$]\n",
    "\n",
    "Dove $cov(X_i, X_j)$ rappresenta la covarianza tra la variabile $X_i$ e la variabile $X_j$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis\n",
    "\n",
    "L'***LDA*** √® un classificatore lineare di tipo bayesiano. L'analisi discriminante lineare √® una generalizzazione della discriminante lineare di Fisher, un per trovare una combinazione lineare di caratteristiche che raggruppano o separano 2 o pi√π classi di oggetti o eventi.\n",
    "\n",
    "Al posto di usare il prodotto di distribuzioni indipendenti Normali come nel Naive Bayes, l'LDA assume che le distribuzioni siano Normali, ma con la stessa matrice di covarianza $\\Sigma$ per tutte le classi.\n",
    "\n",
    "### $\\phi_c(x) = N(x, \\mu_c, \\sigma) = \\frac{1}{|2\\pi\\Sigma|^{1/2}}e^{-\\frac{1}{2}(x-\\mu_c)^T\\Sigma^{-1}(x-\\mu_c)}$\n",
    "\n",
    "Dove la funzione di classificazione √® $f_{LDA}(x)= argmax_{c \\in Y}\\phi_c(x) \\pi_c$\n",
    "\n",
    "Esattamente come Naive Bayes, i parametri nell'LDA sono appresi usando la maximum likelihood, che si riduce all'uso di stime campionarie per la media e la matrice di covarianza:\n",
    "\n",
    "### Class probabilities: $\\pi_c = \\frac{1}{N}{\\sum_{i=1}^N [y_i = c]}$\n",
    "\n",
    "### Class Means: $\\mu_c = \\frac{{\\sum_{i=1}^N [y_i = c]}x_i}{\\sum_{i=1}^N [y_i = c]}$\n",
    "\n",
    "### Shared Covariance: $\\Sigma = \\frac{1}{n}{\\sum_{i=1}^n(x_i-\\mu_c)(x_i-\\mu_c)^T}$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretazione geometrica LDA\n",
    "\n",
    "Il boundary consiste nell'insieme di punti $x$ dove:\n",
    "\n",
    "$log(\\pi_0) - \\frac{1}{2} log(|2\\pi\\Sigma|) - \\frac{1}{2}(x-\\mu_0)^T\\Sigma^{-1}(x-\\mu_0) - log(\\pi_1) + \\frac{1}{2} log(|2\\pi\\Sigma|) + \\frac{1}{2}(x-\\mu_1)^T\\Sigma^{-1}(x-\\mu_1) = 0$\n",
    "\n",
    "Siccome $log(|2\\pi\\Sigma|)$ √® uguale per entrambe le classi, posso semplificare:\n",
    "\n",
    "![LDA](./images/bayesLDA6.png)\n",
    "\n",
    "Questo mostra che il decision boundary √® lineare in x, quindi l'LDA √® un classificatore lineare.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking\n",
    "Il <span style=\"color:gold;\">masking phenomenon</span> descrive una sfida o una limitazione nella capacit√† del modello di scoprire gli argomenti sottostanti in una collezione di documenti quando alcuni argomenti sono meno prevalenti o meno evidenti di altri.\n",
    "\n",
    "L'LDA evita questo fenomeno usando due ***decision boundaries*** 1:\n",
    "\n",
    "![masking_lda](./images/bayesLDA7.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic discriminant analysis\n",
    "\n",
    "Rilassa l'assunzione di LDA che tutte le classi condividano la stessa matrice di covarianza $\\Sigma$. Densit√† di probabilit√† possono avere matrici di covarianza diverse.\n",
    "\n",
    "#### $\\log(\\pi_0)-\\frac{1}{2}\\log(|2\\pi\\Sigma_0|)-\\frac{1}{2}(x-\\mu_0)^T\\Sigma_0^{-1}(x-\\mu_0)-\\log(\\pi_1)+\\frac{1}{2}\\log(|2\\pi\\Sigma_1|)+\\frac{1}{2}(x-\\mu_1)^T\\Sigma_1^{-1}(x-\\mu_1)=0$\n",
    "\n",
    "#### <pre> ________________________________________   _________________________________________</pre>\n",
    "#### <pre>             Boundry per classe 0                 Boundary per classe 1</pre>\n",
    "\n",
    "Corrisponde a un classificatore bayesiano con class conditional parametric multi variate Gaussian Distributions\n",
    "\n",
    "![qda](./images/bayesLDA8.png)\n",
    "\n",
    "# Trade-offs\n",
    "\n",
    "- Velocit√†: la dipendenza quadratica sul dataset **D** rende LDA pi√π lento del Naive Bayes di un fattore D durante allenamento e classificazione\n",
    "- Storage: Il modello richiede $O(D^2C)$ parametri. Questo pu√≤ rappresentare comunque una buona compressione dei dati quando $D << N$\n",
    "- Interpretabilit√†: Il modello ha buona interpretabilit√† dal momento che i parametri $\\mu_c$ corrispondono alle medie delle classi\n",
    "- Accuratezza: L'assunzione dell'LDA sar√† raramente corretta per i problemi reali. Tuttavia, i boundaries lineari introdotti possono spesso performare bene\n",
    "- Dati: l'LDA richieder√† generalmente pi√π dati di $NB$ dal momento che deve stimare $O(D^2C)$ parametri nella matrice di covarianza\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative vs Discriminative Classifiers\n",
    "\n",
    "Il classificatore bayesiano, il Naive bayes e l'LDA sono chiamati <span style=\"color:gold;\">**generative classifiers**</span>, perch√© generano una **joint distribution** $P(X,Y)$ dei vettori $x$ e delle label $y$\n",
    "\n",
    "Generativo significa che tutt'ora che il classificatore ha appreso √® sempre possibile campionare exempi $x$ data la clase $y = c$ usando la distribuzione $p(x|y=c)$ o marginalizzando il joint p(X,Y)\n",
    "\n",
    "√à veramente necessario? No, per costruire un classificatore probabilitstico, tutto quello che dobbiamo modellare √® $P(y|X)\n",
    "\n",
    "I classificatori basati direttamente sulla stima di $P(y|X)$ sono chiamati <span style=\"color:gold;\">**discriminative classifiers**</span> perch√© ignorano la distribuzione di $x$ e si concentrano solo sulle label delle classi $y = c$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "La logistic regression appartiene alla famiglia dei classificatori discriminativi, ovvero quelli che mi permettono di sapere qual √® lo score della classe y dato X. √à comunque un classificatore probabilistico perch√© in output fornisce delle probabilit√† e nello specifico fornisce la ***probabilit√† a posteriori*** che viene modellata direttamente (non applichiamo la regola di bayes, ma modelliamo con l'equazione $P(Y|x)$).\n",
    "\n",
    "Nel caso binario, quindi con sole due classi:\n",
    "\n",
    "## $P(Y=0|x) = \\frac{e^{w^T x+b}}{1+e^{w^T x+b}}$\n",
    "\n",
    "## $P(Y=1|x) = \\frac{1}{1+e^{w^T x+b}}$\n",
    "\n",
    "Se faccio il logaritmo del rapporto tra queste due quantit√† ottengo:\n",
    "\n",
    "## $\\log(\\frac{P(Y=1|x)}{P(Y=0|x)}) = \\log P(Y=1|x) - \\log P(Y=0|x) = w^T x + b$\n",
    "\n",
    "Che √® una funzione lineare di una retta, o piano o iperpiano. Quindi la logistic regression √® un classificatore lineare.\n",
    "\n",
    "Se lo score della classe 0 √® maggiore dello score della classe 1, il rapporto √® maggiore di 1, viceversa se lo score della classe 0 √® pi√π piccolo dello score della classe 1, il rapporto √® minore di 1. Quindi se io faccio il rapporto posso gi√† sapere se faccio parte della classe 0 o della classe 1.\n",
    "\n",
    "Questo si traduce in:\n",
    "- Se $w^T x + b > 0$ allora sono della classe 0\n",
    "- Se $w^T x + b < 0$ allora sono della classe 1\n",
    "\n",
    "Geometricamente, se ho un punto e mi d√† un valore > di 0, vuol dire che sono sopra a questa retta.\n",
    "\n",
    "La funzione di classificatione:\n",
    "\n",
    "## $f_{LR}(x) = argmax_{c \\in ùí¥} P(Y=c|x)$\n",
    "\n",
    "Per calcolarla, prendo ogni formula per $P(Y=0|x)$ e $P(Y=1|x)$, ci metto $x$ dentro, salvo tutti gli score (che sono anche probabilit√†) e scelgo la classe che mi d√† lo score pi√π alto.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Function o sigmoide\n",
    "\n",
    "## $f(x) = \\frac{1}{1+e^{-x}}$\n",
    "\n",
    "oppure\n",
    "\n",
    "## $f(x) = \\frac{e^x}{1+e^{-2x}}$\n",
    "\n",
    "La funzione logistica √® la versione continua di una soglia.\n",
    "\n",
    "\n",
    "Nel caso della Logistic Regression, lo score si calcola facendo $w^Tx+b$, poi viene passato per questa funzione che \"soglia\" questo score. Quindi se questo score √® maggiore di una certa quantit√† viene tirato verso l'alto e se √® minore di una certa quantit√† viene tirato verso il basso.\n",
    "\n",
    "La funzione logistica si usa quasi sempre quando devo trasformare degli score in probabilit√†, poich√© non ho nessuna granzia che $w^Tx+b$ sia una probabilit√† (potrebbe essere > 1). Dopo che vengono passati tra questa funzione logistica i numeri sono tutti tra 0 e 1. \n",
    "\n",
    "![logistic](./images/bayesLDA9.png)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Logistic Regression\n",
    "\n",
    "Nel caso di $K$ classi:\n",
    "\n",
    "## $P(Y=c|x) = \\frac{e^{w_c^T x + b_c}}{1 + \\sum_{l=1}^{K-1} e^{w_l^T x + b_l}}$\n",
    "\n",
    "## $P(Y=K|x) = \\frac{1}{1 + \\sum_{l=1}^{K-1} e^{w_l^T x + b_l}}$\n",
    "\n",
    "Questa volta ho $w_c^T$, ovvero un vettore di parametri $w$ per la classe $c$ + un bias $b_c$ per la classe $c$.\n",
    "\n",
    "Per la classe $K$-esima, l'ultima, a numeratore ho 1.\n",
    "\n",
    "In entrambe a denominatore ho la somma dei numeratori di tutte le classi, perch√© queste sono probabilit√† &rarr; la somma di tutto deve fare 1.\n",
    "\n",
    "La funzione di classificatione √® uguale al caso binario:\n",
    "\n",
    "## $f_{LR}(x) = argmax_{c \\in ùí¥} P(Y=c|x)$\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Logistic Regression\n",
    "\n",
    "Essendo un classificatore statistico si addestra a maximum likelihood, quindi il set di parametri theta di questo oggetto $\\theta = \\{(w_c, b_c), c \\in ùí¥\\}$ sono selezionati per massimizzare la likelihood del dataset $D = \\{(x_i, y_i), i = : n\\}$, dove $x$ √® un vettore di feature e $y$ √® la label della classe appartenente, che contiene $n$ elementi. La likelihood si calcola come la sommatoria di tutti gli elementi del logaritmo della probabilit√† che ho stimato per la classe corretta dato $X=x_i$:\n",
    "\n",
    "## $\\theta_* = argmax_{\\theta} L(\\theta|D) = argmax_{\\theta} \\sum_{i=1}^n P(Y=y_i|X=x_i)$\n",
    "\n",
    "Quindi di tutti gli score che produco, uso la label $y_i$ per scegliere tra tutti score quello della classe che massimizza (?). Massimizzare questa quantit√† vuol dire cercare di avere lo score della classe corretta pi√π alto possibile per tutti gli elementi.\n",
    "\n",
    "Perch√© non c'√® bisogno di fare niente per gli altri score di tutte le classi tranne quello di quella corretta? Perch√© la somma √® sempre 1, quindi se alzo uno score di un po', gli altri devono diminuire.  \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Logistic Regression #2\n",
    "Per imparare devo risolvere un problema di ottimizzazione nel quale devo massimizzare $ \\sum_{i=1}^{n} \\log P(y_i|x_i)$, ovvero trovare il set di parametri $w$ e $b$, per cui questa quantit√† √® massima. Se io faccio il log della likelihood:\n",
    "\n",
    "## $\\log P(y_i|x_i) = \\log \\frac {e^{w^T_c x_i + b}}{1+\\sum_{l=1}^{K-1} e^{w_l^T x + b_l}} = \\log e^{w^T_c x_i + b} - \\log (1+\\sum_{l=1}^{K-1} e^{w_l^T x + b_l})$\n",
    "\n",
    "che diventa:\n",
    "\n",
    "## $w^T_c x_i + b - \\log (1+\\sum_{l=1}^{K-1} e^{w_l^T x + b_l})$\n",
    "\n",
    "Dato il caso binario con due classi, con $y \\in \\{0,1\\}$ e un dataset D, posso riscrivere la likelihood come:\n",
    "\n",
    "## $L(\\theta|D) = \\sum_{i=1}^N y_i log(P(y=1|x)) + (1-y) log(P(y=0|x))$\n",
    "\n",
    "Dove $y_i$ √® un \"attivatore\" che se vale 1, il secondo termine $(1-y) log(P(y=0|x))$ sparisce, mentre se vale 0 sparisce il primo termine $y_i log(P(y=1|x))$.\n",
    "\n",
    "Questo √® un caso particolare nel quale questa equazione √® uguale al negato della **binary cross entropy**.\n",
    "\n",
    "Quindi in generale, **risolvere un problema Maximum likelihood nel caso della logistic regression, se massimizzo la likelihood sto minimizzando la cross entropy** (perch√© la cross entropy √® - la likelihood).\n",
    "\n",
    "---\n",
    "\n",
    "Non essendo risolvibile per mezzo di una strategia analitica, si usa una strategia iterativa, ovvero si usa il <span style=\"color:gold;\">Gradient Descent</span>.\n",
    "\n",
    "L'ingrediente per poter risolver il grandiant descent √® quello di poter calcolare la derivata della nostra funzione obiettivo rispetto a uno qualunque dei parametri.  Nel caso binario otteniamo:\n",
    "\n",
    "## $\\frac{\\partial{L(x_i, \\Theta)}}{\\partial w_k} = (y_i - \\frac{e^{w^T x_i}}{1 + e^{w^T x_i}}) x_{i,k}$\n",
    "\n",
    "- Se io dessi 1 come score alla classe 1 e la label valesse 1 quello tra le parentesi farebbe 0 &rarr; ci ho preso.\n",
    "- Se ho dato come score 0 alla classe 1 e la label valesse 1 quello tra le parentesi farebbe 1 &rarr; ho sbagliato.\n",
    "\n",
    "Quindi questo ci dice quanto sono bravo ad avvicinarmi alla label.\n",
    "\n",
    "Se la label fosse 0 e io fossi bravo, anche nel mio score dovrei avere 0.\n",
    "\n",
    "Il tutto viene moltiplicato per $x_{i,k}$, che √® il valore della feature $k$-esima del mio esempio $i$-esimo.\n",
    "\n",
    "`Da sapere i passaggi per arrivare a questa derivata per l'esame`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradiant descent\n",
    "√à una procedura iterativa per trovare i minimi di una funzione seguendo la pendenza della curva della funzione. \n",
    "\n",
    "La pendenza della funzione √® data dalla derivata della funzione nel punto in cui mi trovo.\n",
    "\n",
    "Suppongo che la soluzione del mio problema di minimo sia un valore $\\theta_j$ che minimizza la funzione:\n",
    "\n",
    "## $\\theta_j = \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} f(\\theta)$\n",
    "\n",
    "Qui inizia un processo iterativo nel quale dico che a ogni step $\\theta_j$ √® uguale a se stesso - $\\alpha$ (che √® un numero) per la derivata della funzione valutata in $\\theta_j$.\n",
    "\n",
    "$\\alpha$ si chiama <span style=\"color:gold;\">learning rate</span> ed √® un numero tra 0 e 1 che dice di quanto mi sto fidando della pendenza.\n",
    "\n",
    "![gradient_descent](./images/bayesLDA10.png)\n",
    "\n",
    "Il gradiant descent arriva a convergenza quando la derivata della funzione √® uguale a 0, ovvero quando mi trovo in un minimo.\n",
    "\n",
    "√à importante per√≤ che per trovare il minimo globale la mia funzione sia convessa cio√® ammetta un unimo minimo perch√© alternativamente ci possono essere tanti punti nei quali la derivata √® 0 ma non sono nel minimo. Se la funzione non √® convessa accetto di fermarmi in un minimo qualunque e quindi locale.\n",
    "\n",
    "In generale il Gradiant Descent pu√≤ essere applicato a tutti i problemi di minimizzazione, purch√© ammetta un minimo.\n",
    "\n",
    "Per calcolare il mio step di update, potrei decidere di usare un elemento solo (derivata della funzione valutata in $x_i$), oppure tutto il dataset, oppure dei pezzetti di dataset:\n",
    "- Se uso un elemento solo io prendo dal mio dataset un elemento a caso $x_i$, valuto il gradiente in quel punto e poi utilizzo quella pendenza per aggiornare il mio set di parametri. Quando calcolo il grandiente in un punto pu√≤ succedere che quel gradiente sia rumoroso a piacere, e non √® detto che per forza che la direzione sia chiaramente verso il minimo della mia funzione &rarr; usare un singolo elemento √® un gradiente poco affidabile.\n",
    "- il miglior gradiente in assoluto ce l'avrei facendo il <span style=\"color:gold;\">Batch Gradient Descent</span>, ovvero calcolando lo step di update come il gradiente medio su tutti gli elementi del dataset. √à molto costoso perch√© per ogni step di update devo calcolare il gradiente su tutto il dataset.\n",
    "- Per ovviare ai costi eccessivi del Batch Gradient Descent si utilizza lo <span style=\"color:gold;\">Stochastic Gradient Descent</span>, che √® una via di mezzo tra i due. Invece di calcolare il gradiente su tutto il dataset, lo calcolo su un piccolo sottoset del dataset, poi faccio la media e applico lo step di update.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate\n",
    "Il learning rate √® un numero che modula quanto ci fidiamo della pendenza data dal gradiente:\n",
    "- se il learning rate √® molto basso faccio degli step molto piccoli &rarr; ci metto molto tempo a convergere\n",
    "- se il learning rate √® alto faccio degli step grossi &rarr; rischio di saltare il minimo e di non convergere\n",
    "\n",
    "![learning_rate](./images/bayesLDA11.png)\n",
    "\n",
    "Valori comuni di learning rate sono $10^{-3}$ o $10^{-4}$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent for binary logistic regression\n",
    "\n",
    "**Input**: dataset D di N elementi, $y \\in \\{0, 1\\}$, con learning rate \\alpha\n",
    "**Output**: parametro di vettori $w$\n",
    "Inizializzo randomicamente i parametri del vettore $w$;\n",
    "Vado avanti fino a che o ho raggiunto il numero massimo di iterazioni oppure sono a convergenza e per ogni iterazione:\n",
    "- Prendo un elemento a caso dal dataset($x_i, y_i$);\n",
    "- Calcolo la derivata della loss rispetto a $w$ ![partial_loss_w](./images/bayesLDA12.png);\n",
    "  - dove ![partial_loss_w2](./images/bayesLDA13.png)\n",
    "- applico il gradiant descent con: $w = w - \\alpha \\frac{\\partial L(x_i, w)}{\\partial w}$\n",
    "- imposto $w = w^{new}$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometry\n",
    "\n",
    "Da un punto di vista geometrico la superficie di separazione della logistic regression √® lineare.\n",
    "\n",
    "Se ho pi√π di due classi √® ancora lineare in modalit√† piece-wise, facendo due classi alla volta. \n",
    "\n",
    "Da un punto di vista di capacit√† di rappresentazione, cio√® di creare superfici di separazione, Logistic Regression e LDA sono equivalenti.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade-offs\n",
    "\n",
    "- Velocit√†: durante l'inferenza, la logistic regression √® pi√π veloce della LDA e di Naive Bayes. L'allenamento √® pi√π lento perch√© si deve applicare il gradient descent.\n",
    "\n",
    "- Parametri: il modello richiede $O(DC) parametri, ovvero un vettore per K-1 classi. Ha molti meno parametri rispetto all'LDA.\n",
    "\n",
    "- Interpretabilit√†: √® molto interpretabile perch√© a ogni feature nel mio vettore $w$ viene attribuito uno score. Questo score pu√≤ essere anche interpretato come l'importanza di quella feature.\n",
    "\n",
    "- Accuratezza: la logistic regression funziona meglio dell'LDA quando ho vettori di feature molto grandi e pochi dati\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
