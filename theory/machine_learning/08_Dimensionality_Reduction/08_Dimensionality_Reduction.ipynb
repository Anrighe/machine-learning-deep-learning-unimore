{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Redcution\n",
    "\n",
    "I metodi di riduzione delle dimensioni cercando di ridurre il numero di feature con cui è rappresentato un elemento senza perdere capacità descrittiva (es risolvo il problma iniziale che aveva elementi da 1000 feature con elementi da 100 feature).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multidimensional Scaling (MDS)\n",
    "\n",
    "MULTI-DIMENSIONAL SCALING (MDS)\n",
    "• Map the items in a k-dimensional space trying to minimize the stress\n",
    "• Steepest Descent algorithm:\n",
    "• Start with an assignment\n",
    "• Minimize stress by moving points\n",
    "• But the running time is O(N2) and O(N) to add a new item\n",
    "\n",
    "j\n",
    "ij\n",
    "i j\n",
    "ij ij\n",
    "d o o and d o o\n",
    "d\n",
    "d d\n",
    "s\n",
    "\n",
    "Parto da un dataset iniziale in cui ogni punto è rappresentato con le sue $K$ feature originali. Voglio avere una nuova rappresentazione (in uno spazio di dimensione $d$) in cui ogni punto è rappresentato con le sue $d$ feature e voglio minimizzare lo <span style=\"color:gold;\">stress</span>:\n",
    "\n",
    "## $stress = \\sqrt{\\frac{\\sum_{i,j} (d_{ij} - \\hat{d}_{ij})^2}{\\sum_{i,j} d_{ij}^2}} , d_{ij} = | o_j - o_i | $ e $ \\overset{\\frown}{d_{ij}} = | \\overset{\\frown}{o}_j - \\overset{\\frown}{o}_i | $\n",
    "\n",
    "Dove lo stress è la distanza tra i punti nel nuovo spazio e la distanza tra i punti nel vecchio spazio, ovvero quanto le distanze variano. \n",
    "\n",
    "- $o$ è la rappresentazione dello spazio originale\n",
    "- $o_j - o_i$ è la distanza tra l'elemento i-esimo e l'elemento j-esimo nello spazio ***originale***\n",
    "- $\\overset{\\frown}{o}$ è la rappresentazione dello spazio ridotto\n",
    "- $\\overset{\\frown}{o}_j - \\overset{\\frown}{o}_i$ è la distanza tra l'elemento i-esimo e l'elemento j-esimo nello spazio ***ridotto***\n",
    "- Lo stress si calcola come somma della differenza di ogni coppia di elmeneti $i$, $j$ rispettivamente della distanza trasformata e di quella originale diviso una costante di normalizzazione.\n",
    "\n",
    "Io vorrei avere un nuovo spazio in cui le distanze tra i punti siano le stesse, ma non è possibile. Quindi cerco di minimizzare lo stress, ovvero cerco di minimizzare la differenza tra le distanze nello spazio originale e quelle nello spazio ridotto.\n",
    "\n",
    "Si risolve in modo euristico per mezzo dello <span style=\"color:gold;\">Steepest Descent</span>:\n",
    "- Parto da una rappresentazione iniziale (assegno delle coordinate a caso a tutti i punti)\n",
    "- Valuta lo stress\n",
    "- Prende un punto a caso, lo muove nella direzione che diminuisce lo stress\n",
    "- Ripeti fino a quando lo stress non è minore di una soglia\n",
    "\n",
    "Questa è un'euristica perché non ho la garanzia che muovendo un punto non mi allontani dalla mia soluzione &rarr; no garanzia di convergenza\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "Tutte le volte che si riducono le dimensioni di un dataset, si introduce il concetto di embedding.\n",
    "\n",
    "Supponendo di avere una matrice delle distanze D che misura la distanza tra tutti gli elementi del dataset: ***il concetto di embedding implica la necessità di incorporare i miei punti in uno spazio a dimensione minore in modo tale che le distanze tra due punti dello spazio originale sia più vicino possibile alla distanza tra i due punti nello spazio ridotto***:\n",
    "\n",
    "### $D(i,j) \\approx D^{'}(i,j)$\n",
    "\n",
    "Questo tipo di embedding si chiama <span style=\"color:gold;\">isometrico</span> cioè un embedding che conserva le distanze:\n",
    "- $D^{'}(F(i),F(j)) = D(i,j)$\n",
    "\n",
    "Un altro tipo di embedding è il <span style=\"color:gold;\">contrattivo</span> cioè un embedding che non conserva le distanze:\n",
    "- $D^{'}(F(i),F(j)) \\leq D(i,j)$\n",
    "\n",
    "A seconda di come viene realizzata questa trasformazione dei punti, gli embedding si dividono in:\n",
    "- ***Lineari***: i punti vengono proiettati in uno spazio di dimensione minore da una **trasformazione lineare** (tendenzialmente prodotto riga per colonna)\n",
    "- ***Non lineari***: i punti sono proiettati su un nuovo spazio in modo non lineare \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "Il ***PCA*** è un metodo lineare di riduzione delle dimensioni."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
